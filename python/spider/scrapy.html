<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy框架 | 📖Documents</title>
    <meta name="generator" content="VuePress 1.5.4">
    <script>
        var _mtac = {"senseQuery":1};
        (function() {
            var mta = document.createElement("script");
            mta.src = "//pingjs.qq.com/h5/stats.js?v2.0.4";
            mta.setAttribute("name", "MTAH5");
            mta.setAttribute("sid", "500727760");
            mta.setAttribute("cid", "500727761");
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(mta, s);
        })();
        </script>
    <meta name="description" content="This is a personal document library for development work">
    <link rel="preload" href="/assets/css/0.styles.715b4171.css" as="style"><link rel="preload" href="/assets/js/app.3fe91e28.js" as="script"><link rel="preload" href="/assets/js/2.c070ac21.js" as="script"><link rel="preload" href="/assets/js/83.82c27af0.js" as="script"><link rel="prefetch" href="/assets/js/10.d18a15da.js"><link rel="prefetch" href="/assets/js/100.0759928e.js"><link rel="prefetch" href="/assets/js/101.51f5a267.js"><link rel="prefetch" href="/assets/js/102.39963031.js"><link rel="prefetch" href="/assets/js/103.15350d97.js"><link rel="prefetch" href="/assets/js/104.8b5dc923.js"><link rel="prefetch" href="/assets/js/105.edfd9c1e.js"><link rel="prefetch" href="/assets/js/106.8886cea4.js"><link rel="prefetch" href="/assets/js/107.dc92f9c5.js"><link rel="prefetch" href="/assets/js/108.e0d98803.js"><link rel="prefetch" href="/assets/js/109.3553b6b4.js"><link rel="prefetch" href="/assets/js/11.cd6d3eb9.js"><link rel="prefetch" href="/assets/js/110.bf4da3de.js"><link rel="prefetch" href="/assets/js/111.51f19fa1.js"><link rel="prefetch" href="/assets/js/112.11b803be.js"><link rel="prefetch" href="/assets/js/113.92ddd789.js"><link rel="prefetch" href="/assets/js/114.7eeca156.js"><link rel="prefetch" href="/assets/js/115.587e685b.js"><link rel="prefetch" href="/assets/js/116.c048ce4b.js"><link rel="prefetch" href="/assets/js/117.0a1bb830.js"><link rel="prefetch" href="/assets/js/118.5a46b6bc.js"><link rel="prefetch" href="/assets/js/119.c12c9c8a.js"><link rel="prefetch" href="/assets/js/12.66ef900a.js"><link rel="prefetch" href="/assets/js/120.a0204f93.js"><link rel="prefetch" href="/assets/js/121.12989cfc.js"><link rel="prefetch" href="/assets/js/122.2b8cdd9e.js"><link rel="prefetch" href="/assets/js/123.dbc2d9dc.js"><link rel="prefetch" href="/assets/js/124.a97579d7.js"><link rel="prefetch" href="/assets/js/125.f9e45a2f.js"><link rel="prefetch" href="/assets/js/126.db46b9dc.js"><link rel="prefetch" href="/assets/js/127.e2df056a.js"><link rel="prefetch" href="/assets/js/128.ebefc7fa.js"><link rel="prefetch" href="/assets/js/129.28b7f0a4.js"><link rel="prefetch" href="/assets/js/13.2f3a2dcc.js"><link rel="prefetch" href="/assets/js/130.ca2b1ed6.js"><link rel="prefetch" href="/assets/js/131.5a10d800.js"><link rel="prefetch" href="/assets/js/132.df96fad9.js"><link rel="prefetch" href="/assets/js/133.bd5f9895.js"><link rel="prefetch" href="/assets/js/134.18b0e11b.js"><link rel="prefetch" href="/assets/js/135.f3d4f0d7.js"><link rel="prefetch" href="/assets/js/136.f53b7cbb.js"><link rel="prefetch" href="/assets/js/137.e993810e.js"><link rel="prefetch" href="/assets/js/138.3fac51bc.js"><link rel="prefetch" href="/assets/js/139.7c3fb270.js"><link rel="prefetch" href="/assets/js/14.8085e835.js"><link rel="prefetch" href="/assets/js/140.493a4662.js"><link rel="prefetch" href="/assets/js/141.5da03bb5.js"><link rel="prefetch" href="/assets/js/142.d5bdbdef.js"><link rel="prefetch" href="/assets/js/143.8b521623.js"><link rel="prefetch" href="/assets/js/144.8556fe8f.js"><link rel="prefetch" href="/assets/js/145.9be39567.js"><link rel="prefetch" href="/assets/js/146.0c7c83d0.js"><link rel="prefetch" href="/assets/js/147.7f2a2ea0.js"><link rel="prefetch" href="/assets/js/148.3ee3f94d.js"><link rel="prefetch" href="/assets/js/149.de13d92e.js"><link rel="prefetch" href="/assets/js/15.be86a7f2.js"><link rel="prefetch" href="/assets/js/150.ec44debf.js"><link rel="prefetch" href="/assets/js/151.0b03f98a.js"><link rel="prefetch" href="/assets/js/152.c2b8c373.js"><link rel="prefetch" href="/assets/js/153.22007bf8.js"><link rel="prefetch" href="/assets/js/154.a426a75e.js"><link rel="prefetch" href="/assets/js/155.c1f2107f.js"><link rel="prefetch" href="/assets/js/156.a1d1cbca.js"><link rel="prefetch" href="/assets/js/157.c8b798b1.js"><link rel="prefetch" href="/assets/js/158.e5b2c63e.js"><link rel="prefetch" href="/assets/js/159.22801709.js"><link rel="prefetch" href="/assets/js/16.e2121685.js"><link rel="prefetch" href="/assets/js/160.501bc4f4.js"><link rel="prefetch" href="/assets/js/161.8e844d42.js"><link rel="prefetch" href="/assets/js/162.277dcb55.js"><link rel="prefetch" href="/assets/js/163.9e01486a.js"><link rel="prefetch" href="/assets/js/164.c1218267.js"><link rel="prefetch" href="/assets/js/165.aaa90692.js"><link rel="prefetch" href="/assets/js/166.b2cbdccd.js"><link rel="prefetch" href="/assets/js/167.211403e4.js"><link rel="prefetch" href="/assets/js/168.8c68ef4f.js"><link rel="prefetch" href="/assets/js/169.2b7469c6.js"><link rel="prefetch" href="/assets/js/17.cf7d33cc.js"><link rel="prefetch" href="/assets/js/170.0dda19bd.js"><link rel="prefetch" href="/assets/js/171.a8b0f1cb.js"><link rel="prefetch" href="/assets/js/172.103726e8.js"><link rel="prefetch" href="/assets/js/173.2ee472ea.js"><link rel="prefetch" href="/assets/js/174.29dadab2.js"><link rel="prefetch" href="/assets/js/175.2c7b9f77.js"><link rel="prefetch" href="/assets/js/176.3158c49a.js"><link rel="prefetch" href="/assets/js/177.605afad9.js"><link rel="prefetch" href="/assets/js/178.b8bcb7d7.js"><link rel="prefetch" href="/assets/js/179.1509ef88.js"><link rel="prefetch" href="/assets/js/18.6628d58e.js"><link rel="prefetch" href="/assets/js/180.682ee52f.js"><link rel="prefetch" href="/assets/js/181.e4b4c2c8.js"><link rel="prefetch" href="/assets/js/182.43640e9e.js"><link rel="prefetch" href="/assets/js/183.88ebb9d2.js"><link rel="prefetch" href="/assets/js/184.90fca6c0.js"><link rel="prefetch" href="/assets/js/185.eed8ac16.js"><link rel="prefetch" href="/assets/js/186.54cbecfe.js"><link rel="prefetch" href="/assets/js/187.bd4109f3.js"><link rel="prefetch" href="/assets/js/188.20974229.js"><link rel="prefetch" href="/assets/js/189.718207c4.js"><link rel="prefetch" href="/assets/js/19.b574562f.js"><link rel="prefetch" href="/assets/js/190.16f0c45b.js"><link rel="prefetch" href="/assets/js/191.093d0d3c.js"><link rel="prefetch" href="/assets/js/192.54c97f1c.js"><link rel="prefetch" href="/assets/js/193.4a2b11dd.js"><link rel="prefetch" href="/assets/js/194.deaddb97.js"><link rel="prefetch" href="/assets/js/195.6798059d.js"><link rel="prefetch" href="/assets/js/196.16ad68e0.js"><link rel="prefetch" href="/assets/js/197.c47562e6.js"><link rel="prefetch" href="/assets/js/198.5e04eed3.js"><link rel="prefetch" href="/assets/js/199.0f812132.js"><link rel="prefetch" href="/assets/js/20.5909f399.js"><link rel="prefetch" href="/assets/js/200.071d3ed7.js"><link rel="prefetch" href="/assets/js/201.4749a540.js"><link rel="prefetch" href="/assets/js/202.4c1c2b02.js"><link rel="prefetch" href="/assets/js/203.b6b02896.js"><link rel="prefetch" href="/assets/js/204.f43c09c5.js"><link rel="prefetch" href="/assets/js/205.eabf31cd.js"><link rel="prefetch" href="/assets/js/206.5c4c62d5.js"><link rel="prefetch" href="/assets/js/207.babcfe6c.js"><link rel="prefetch" href="/assets/js/208.ed78ea3a.js"><link rel="prefetch" href="/assets/js/209.ad279e62.js"><link rel="prefetch" href="/assets/js/21.2a8c6d3a.js"><link rel="prefetch" href="/assets/js/210.be90083c.js"><link rel="prefetch" href="/assets/js/211.5165db9b.js"><link rel="prefetch" href="/assets/js/212.590acf89.js"><link rel="prefetch" href="/assets/js/213.f48fc347.js"><link rel="prefetch" href="/assets/js/214.569e8336.js"><link rel="prefetch" href="/assets/js/215.65735ab1.js"><link rel="prefetch" href="/assets/js/216.f7a3911d.js"><link rel="prefetch" href="/assets/js/217.92e052f4.js"><link rel="prefetch" href="/assets/js/218.943356a6.js"><link rel="prefetch" href="/assets/js/219.ffa28353.js"><link rel="prefetch" href="/assets/js/22.a4151c9a.js"><link rel="prefetch" href="/assets/js/220.d74edb41.js"><link rel="prefetch" href="/assets/js/23.b08ad2f3.js"><link rel="prefetch" href="/assets/js/24.c20e1c8b.js"><link rel="prefetch" href="/assets/js/25.951a9228.js"><link rel="prefetch" href="/assets/js/26.92ac2d37.js"><link rel="prefetch" href="/assets/js/27.b12508b5.js"><link rel="prefetch" href="/assets/js/28.9f08e837.js"><link rel="prefetch" href="/assets/js/29.89cac4ef.js"><link rel="prefetch" href="/assets/js/3.50c8fd17.js"><link rel="prefetch" href="/assets/js/30.e5fa282e.js"><link rel="prefetch" href="/assets/js/31.06f714d6.js"><link rel="prefetch" href="/assets/js/32.6f6901c9.js"><link rel="prefetch" href="/assets/js/33.6b8490b7.js"><link rel="prefetch" href="/assets/js/34.96cd59b5.js"><link rel="prefetch" href="/assets/js/35.190a3b4e.js"><link rel="prefetch" href="/assets/js/36.05c171ae.js"><link rel="prefetch" href="/assets/js/37.dee69a13.js"><link rel="prefetch" href="/assets/js/38.2d47abfa.js"><link rel="prefetch" href="/assets/js/39.015e3303.js"><link rel="prefetch" href="/assets/js/4.1477a7aa.js"><link rel="prefetch" href="/assets/js/40.e264423f.js"><link rel="prefetch" href="/assets/js/41.e4ab88dd.js"><link rel="prefetch" href="/assets/js/42.9944d882.js"><link rel="prefetch" href="/assets/js/43.1fa1f105.js"><link rel="prefetch" href="/assets/js/44.cdbbde0c.js"><link rel="prefetch" href="/assets/js/45.6a4d2a0d.js"><link rel="prefetch" href="/assets/js/46.f59df48a.js"><link rel="prefetch" href="/assets/js/47.ce173dae.js"><link rel="prefetch" href="/assets/js/48.3586eab5.js"><link rel="prefetch" href="/assets/js/49.673d9ddb.js"><link rel="prefetch" href="/assets/js/5.6c075f1a.js"><link rel="prefetch" href="/assets/js/50.a291094c.js"><link rel="prefetch" href="/assets/js/51.444a416f.js"><link rel="prefetch" href="/assets/js/52.363a8616.js"><link rel="prefetch" href="/assets/js/53.d6bb5255.js"><link rel="prefetch" href="/assets/js/54.e48818e0.js"><link rel="prefetch" href="/assets/js/55.889cdc19.js"><link rel="prefetch" href="/assets/js/56.e0c6e1f8.js"><link rel="prefetch" href="/assets/js/57.be035872.js"><link rel="prefetch" href="/assets/js/58.f2b4bb49.js"><link rel="prefetch" href="/assets/js/59.a41beeed.js"><link rel="prefetch" href="/assets/js/6.840ee6d2.js"><link rel="prefetch" href="/assets/js/60.c2c7cce1.js"><link rel="prefetch" href="/assets/js/61.b5569b83.js"><link rel="prefetch" href="/assets/js/62.a990c686.js"><link rel="prefetch" href="/assets/js/63.58c12e1c.js"><link rel="prefetch" href="/assets/js/64.a0baa0df.js"><link rel="prefetch" href="/assets/js/65.5dfbf0fd.js"><link rel="prefetch" href="/assets/js/66.cfd8adf8.js"><link rel="prefetch" href="/assets/js/67.2a209dcc.js"><link rel="prefetch" href="/assets/js/68.5112ac96.js"><link rel="prefetch" href="/assets/js/69.b6fa5912.js"><link rel="prefetch" href="/assets/js/7.d328cc90.js"><link rel="prefetch" href="/assets/js/70.ba4de141.js"><link rel="prefetch" href="/assets/js/71.aa0a8dcd.js"><link rel="prefetch" href="/assets/js/72.54696f4f.js"><link rel="prefetch" href="/assets/js/73.1b533e98.js"><link rel="prefetch" href="/assets/js/74.d4eaafb7.js"><link rel="prefetch" href="/assets/js/75.49ae4bd8.js"><link rel="prefetch" href="/assets/js/76.0363e380.js"><link rel="prefetch" href="/assets/js/77.13e05c3e.js"><link rel="prefetch" href="/assets/js/78.a19ec8ff.js"><link rel="prefetch" href="/assets/js/79.4a9a3774.js"><link rel="prefetch" href="/assets/js/8.9d679f8c.js"><link rel="prefetch" href="/assets/js/80.efb5b1ca.js"><link rel="prefetch" href="/assets/js/81.3eae8753.js"><link rel="prefetch" href="/assets/js/82.510938cc.js"><link rel="prefetch" href="/assets/js/84.658fbca3.js"><link rel="prefetch" href="/assets/js/85.7852cc0a.js"><link rel="prefetch" href="/assets/js/86.aad38ee2.js"><link rel="prefetch" href="/assets/js/87.a054e492.js"><link rel="prefetch" href="/assets/js/88.0143a21f.js"><link rel="prefetch" href="/assets/js/89.6cd4be63.js"><link rel="prefetch" href="/assets/js/9.e9379d94.js"><link rel="prefetch" href="/assets/js/90.4636eff4.js"><link rel="prefetch" href="/assets/js/91.80a2ee37.js"><link rel="prefetch" href="/assets/js/92.62467c47.js"><link rel="prefetch" href="/assets/js/93.a202fd5d.js"><link rel="prefetch" href="/assets/js/94.29f460e5.js"><link rel="prefetch" href="/assets/js/95.adbd1d9e.js"><link rel="prefetch" href="/assets/js/96.538fff42.js"><link rel="prefetch" href="/assets/js/97.ff52d8b3.js"><link rel="prefetch" href="/assets/js/98.88beff1a.js"><link rel="prefetch" href="/assets/js/99.fd9ff331.js">
    <link rel="stylesheet" href="/assets/css/0.styles.715b4171.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">📖Documents</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow down"></span></button> <button type="button" aria-label="⚡系列文章" class="mobile-dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow down"></span></button> <button type="button" aria-label="⚡系列文章" class="mobile-dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>网络请求</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/network-request/http.html" class="sidebar-link">HTTP协议</a></li><li><a href="/python/network-request/urllib.html" class="sidebar-link">urllib库</a></li><li><a href="/python/network-request/requests.html" class="sidebar-link">requests库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据提取</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-extraction/xpath.html" class="sidebar-link">XPath语法</a></li><li><a href="/python/data-extraction/lxml.html" class="sidebar-link">lxml库</a></li><li><a href="/python/data-extraction/beautifulsoup.html" class="sidebar-link">BeautifulSoup库</a></li><li><a href="/python/data-extraction/regex.html" class="sidebar-link">Python中的正则表达式</a></li><li><a href="/python/data-extraction/python-re.html" class="sidebar-link">re模块</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据存储</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-storage/json.html" class="sidebar-link">json文件处理</a></li><li><a href="/python/data-storage/csv.html" class="sidebar-link">csv文件处理</a></li><li><a href="/python/data-storage/pymysql.html" class="sidebar-link">Python操作MySQL数据库</a></li><li><a href="/python/data-storage/mongodb.html" class="sidebar-link">Python操作MongoDB数据库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫进阶</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/multithreading.html" class="sidebar-link">多线程爬虫</a></li><li><a href="/python/spider/selenium.html" class="sidebar-link">动态网页爬虫</a></li><li><a href="/python/spider/tesseract.html" class="sidebar-link">图形验证码识别</a></li><li><a href="/python/spider/scrapy.html" aria-current="page" class="active sidebar-link">Scrapy框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架介绍" class="sidebar-link">Scrapy框架介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架模块功能" class="sidebar-link">Scrapy框架模块功能</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy安装和文档" class="sidebar-link">Scrapy安装和文档</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy快速入门" class="sidebar-link">Scrapy快速入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建项目" class="sidebar-link">创建项目</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#目录结构介绍" class="sidebar-link">目录结构介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#使用scrapy框架爬取糗事百科段子例子" class="sidebar-link">使用Scrapy框架爬取糗事百科段子例子</a></li></ul></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#jsonitemexporter和jsonlinesitemexporter" class="sidebar-link">JsonItemExporter和JsonLinesItemExporter</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy爬虫注意事项" class="sidebar-link">Scrapy爬虫注意事项</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#crawlspider" class="sidebar-link">CrawlSpider</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建crawlspider爬虫" class="sidebar-link">创建CrawlSpider爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#linkextractors链接提取器" class="sidebar-link">LinkExtractors链接提取器</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#rule规则类" class="sidebar-link">Rule规则类</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy-shell" class="sidebar-link">Scrapy Shell</a></li></ul></li><li><a href="/python/spider/scrapy-redis.html" class="sidebar-link">Scrapy-Redis分布式爬虫</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="scrapy框架"><a href="#scrapy框架" class="header-anchor">#</a> Scrapy框架</h1> <h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="header-anchor">#</a> Scrapy框架介绍</h2> <p>写一个爬虫，需要做很多的事情，比如：发送网络请求、数据解析、数据存储、反反爬虫机制(ip代理，设置请求头等)、异步请求等等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此scrapy把一些基础的东西都封装好了，在scrapy框架上开发爬虫可以变得更加的高效，爬取效率和开发效率得到提升。</p> <h2 id="scrapy框架模块功能"><a href="#scrapy框架模块功能" class="header-anchor">#</a> Scrapy框架模块功能</h2> <ul><li>Scrapy Engine（引擎）：Scrapy框架的核心部分。负责在Spider和ItemPipeline、Downloader、Scheduler中间通信、传递数据等。</li> <li>Spider（爬虫）：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li> <li>Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li> <li>Downloader（下载器）：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li> <li>Item Pipeline（管道）：负责将Spider（爬虫）传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li> <li>Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件。</li> <li>Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件。</li></ul> <h2 id="scrapy安装和文档"><a href="#scrapy安装和文档" class="header-anchor">#</a> Scrapy安装和文档</h2> <ul><li>安装：通过 <code>pip install scrapy</code> 即可安装。
<ul><li>在ubuntu上安装scrapy之前，需要先安装以下依赖：<code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过 <code>pip install scrapy</code> 安装。</li> <li>如果在windows系统下，提示这个错误ModuleNotFoundError: No module named 'win32api'，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li></ul></li> <li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener noreferrer">http://doc.scrapy.org/en/latest<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener noreferrer">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="scrapy快速入门"><a href="#scrapy快速入门" class="header-anchor">#</a> Scrapy快速入门</h2> <h3 id="创建项目"><a href="#创建项目" class="header-anchor">#</a> 创建项目</h3> <p>要使用Scrapy框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p> <p><code>scrapy startproject [项目名称]</code></p> <h3 id="目录结构介绍"><a href="#目录结构介绍" class="header-anchor">#</a> 目录结构介绍</h3> <ul><li>items.py：用来存放爬虫爬取下来数据的模型。</li> <li>middlewares.py：用来存放各种中间件的文件。</li> <li>pipelines.py：用来将items的模型存储到本地磁盘中。</li> <li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li> <li>scrapy.cfg：项目的配置文件。</li> <li>spiders包：以后所有的爬虫，都是存放到这个里面。</li></ul> <h3 id="使用scrapy框架爬取糗事百科段子例子"><a href="#使用scrapy框架爬取糗事百科段子例子" class="header-anchor">#</a> 使用Scrapy框架爬取糗事百科段子例子</h3> <h4 id="使用命令创建一个爬虫"><a href="#使用命令创建一个爬虫" class="header-anchor">#</a> 使用命令创建一个爬虫</h4> <p><code>scrapy gensipder qsbk &quot;qiushibaike.com&quot;</code></p> <p>创建了一个名字叫做 qsbk 的爬虫，并且能爬取的网页只会限制在 qiushibaike.com 这个域名下。</p> <h4 id="爬虫代码解析"><a href="#爬虫代码解析" class="header-anchor">#</a> 爬虫代码解析</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。</p> <p>要创建一个Spider，那么必须自定义一个类，继承自scrapy.Spider，然后在这个类中定义三个属性和一个方法。</p> <ul><li>name：这个爬虫的名字，名字必须是唯一的。</li> <li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li> <li>start_urls：爬虫从这个变量中的url开始。</li> <li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个parse方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li></ul> <h4 id="修改settings-py代码"><a href="#修改settings-py代码" class="header-anchor">#</a> 修改settings.py代码</h4> <p>在做一个爬虫之前，一定要记得修改setttings.py中的设置。两个地方是强烈建议设置的。</p> <ul><li>ROBOTSTXT_OBEY设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li> <li>DEFAULT_REQUEST_HEADERS添加User-Agent。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li></ul> <h4 id="完成的爬虫代码"><a href="#完成的爬虫代码" class="header-anchor">#</a> 完成的爬虫代码</h4> <h5 id="爬虫部分代码"><a href="#爬虫部分代码" class="header-anchor">#</a> 爬虫部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>response<span class="token punctuation">.</span>html <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>unified <span class="token keyword">import</span> SelectorList
<span class="token keyword">from</span> qsbk<span class="token punctuation">.</span>items <span class="token keyword">import</span> QsbkItem

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk_spider'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/page/1/'</span><span class="token punctuation">]</span>
    base_domain <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duanziDivs <span class="token operator">=</span> contentLeft <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//div[@id='content-left']/div&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> duanzidiv <span class="token keyword">in</span> duanziDivs<span class="token punctuation">:</span>
            author <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//h2/text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class='content']//text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># duanzi = {&quot;author&quot;:author,&quot;content&quot;:content}</span>
            <span class="token comment"># yield duanzi</span>

            item <span class="token operator">=</span> QsbkItem<span class="token punctuation">(</span>author<span class="token operator">=</span>author<span class="token punctuation">,</span>content<span class="token operator">=</span>content<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item
        next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ul[@class='pagination']/li[last()]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> next_url<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_domain <span class="token operator">+</span> next_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h5 id="items-py部分代码"><a href="#items-py部分代码" class="header-anchor">#</a> items.py部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h5 id="pipeline部分代码"><a href="#pipeline部分代码" class="header-anchor">#</a> pipeline部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 方式1</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item_json <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>item_json<span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式2</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式3</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonLinesItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><h4 id="运行scrapy项目"><a href="#运行scrapy项目" class="header-anchor">#</a> 运行scrapy项目</h4> <p>运行scrapy项目。需要在终端，进入项目所在的路径，然后 <code>scrapy crawl [爬虫名字]</code> 即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做 start.py，然后在这个文件中填入以下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl qsbk&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="jsonitemexporter和jsonlinesitemexporter"><a href="#jsonitemexporter和jsonlinesitemexporter" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExporter</h2> <ul><li>保存json数据的时候，可以使用这两个类，让操作变得更简单</li> <li><code>JsonItemExporter</code>：每次把数据添加到内存中，最后统一写入磁盘，存储的数据是一个满足json规则的数据，数据量比较大，比较耗内存</li> <li><code>JsonLinesItemExporter</code>：每次调用<code>export_item</code>的时候把这个item存储到磁盘，每一个字典是一行，整个文件不是一个满足json格式的文件，每次处理初级的时候直接存储到硬盘，不耗内存，数据比较安全</li></ul> <h2 id="scrapy爬虫注意事项"><a href="#scrapy爬虫注意事项" class="header-anchor">#</a> Scrapy爬虫注意事项</h2> <ul><li>response 是一个<code>from scrapy.http.response.html.HtmlResponse</code>对象，可以执行<code>xpath</code>和<code>css</code>语法提取数据</li> <li>提取出来的数据是一个<code>Selector</code>或者<code>SelectorList</code>对象，如果想要获取其中的字符串，应该执行<code>getall</code>或者<code>get</code>方法</li> <li>getall方法：获取<code>Selector</code>中所有文本，返回的是一个列表</li> <li>get方法：获取的是<code>Selector</code>中的第一个文本，返回的是str类型</li> <li>如果数据解析回来要传给pipelines处理，可以使用<code>yield</code>来返回，或者是添加所有的item，统一使用<code>return</code>返回</li> <li>item：在<code>item.py</code>中定义好模型，不要使用字典</li> <li>pipelines：这个是专门一从来保存数据的，其中有三个方法是会被经常用到的。要激活pipelines，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code> <ul><li><code>open_spider</code>：当爬虫被打开的时候执行</li> <li><code>process_item</code>：当爬虫有item传过来的时候会被调用</li> <li><code>close_spider</code>：当爬虫关闭的时候被调用</li></ul></li></ul> <h2 id="crawlspider"><a href="#crawlspider" class="header-anchor">#</a> CrawlSpider</h2> <p>在糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过CrawlSpider来帮我们完成了。CrawlSpider继承自Spider，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的yield Request。</p> <h2 id="创建crawlspider爬虫"><a href="#创建crawlspider爬虫" class="header-anchor">#</a> 创建CrawlSpider爬虫</h2> <p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建CrawlSpider爬虫，那么应该通过以下命令创建：</p> <p><code>scrapy genspider -c crawl [爬虫名字] [域名]</code></p> <h2 id="linkextractors链接提取器"><a href="#linkextractors链接提取器" class="header-anchor">#</a> LinkExtractors链接提取器</h2> <p>使用LinkExtractors可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给LinkExtractors，他会在所有爬的页面中找到满足规则的url，实现自动的爬取。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_extensions <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tags <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    attrs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    canonicalize <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    unique <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    process_value <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li> <li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li> <li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li> <li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li> <li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li></ul> <h2 id="rule规则类"><a href="#rule规则类" class="header-anchor">#</a> Rule规则类</h2> <p>定义爬虫的规则类。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>Rule<span class="token punctuation">(</span>
    link_extractor<span class="token punctuation">,</span>
    callback <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    cb_kwargs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    follow <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_links <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_request <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>link_extractor：一个LinkExtractor对象，用于定义爬取规则。</li> <li>callback：满足这个规则的url，应该要执行哪个回调函数。因为CrawlSpider使用了parse作为回调函数，因此不要覆盖parse作为回调函数自己的回调函数。</li> <li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li> <li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li></ul> <h2 id="scrapy-shell"><a href="#scrapy-shell" class="header-anchor">#</a> Scrapy Shell</h2> <p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为scrapy是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此Scrapy提供了一个shell，用来方便的测试规则</p> <p>打开cmd终端，进入到Scrapy项目所在的目录，然后进入到scrapy框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的parse方法中一样使用了。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/meowv/docs/edit/master//python/spider/scrapy.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">7 days ago</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/tesseract.html" class="prev">
        图形验证码识别
      </a></span> <span class="next"><a href="/python/spider/scrapy-redis.html">
        Scrapy-Redis分布式爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.3fe91e28.js" defer></script><script src="/assets/js/2.c070ac21.js" defer></script><script src="/assets/js/83.82c27af0.js" defer></script>
  </body>
</html>
