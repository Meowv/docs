<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy框架 | 📖Documents</title>
    <meta name="generator" content="VuePress 1.5.4">
    <script>
        var _mtac = {"senseQuery":1};
        (function() {
            var mta = document.createElement("script");
            mta.src = "//pingjs.qq.com/h5/stats.js?v2.0.4";
            mta.setAttribute("name", "MTAH5");
            mta.setAttribute("sid", "500727760");
            mta.setAttribute("cid", "500727761");
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(mta, s);
        })();
        </script>
    <meta name="description" content="This is a personal document library for development work">
    <link rel="preload" href="/assets/css/0.styles.715b4171.css" as="style"><link rel="preload" href="/assets/js/app.75313780.js" as="script"><link rel="preload" href="/assets/js/2.2c885d95.js" as="script"><link rel="preload" href="/assets/js/79.102a7fb7.js" as="script"><link rel="prefetch" href="/assets/js/10.1d770918.js"><link rel="prefetch" href="/assets/js/100.02e1d92c.js"><link rel="prefetch" href="/assets/js/101.3d826f09.js"><link rel="prefetch" href="/assets/js/102.895d9ae3.js"><link rel="prefetch" href="/assets/js/103.0ebbc9b3.js"><link rel="prefetch" href="/assets/js/104.290b9169.js"><link rel="prefetch" href="/assets/js/105.9190bc64.js"><link rel="prefetch" href="/assets/js/106.0c55a332.js"><link rel="prefetch" href="/assets/js/107.1bfbedf7.js"><link rel="prefetch" href="/assets/js/108.99600257.js"><link rel="prefetch" href="/assets/js/109.bfd68df8.js"><link rel="prefetch" href="/assets/js/11.cc469c7e.js"><link rel="prefetch" href="/assets/js/110.89234617.js"><link rel="prefetch" href="/assets/js/111.a076efe7.js"><link rel="prefetch" href="/assets/js/112.8da4dbf5.js"><link rel="prefetch" href="/assets/js/113.2e07fb15.js"><link rel="prefetch" href="/assets/js/114.66ab037a.js"><link rel="prefetch" href="/assets/js/115.fb4c335c.js"><link rel="prefetch" href="/assets/js/116.4126ca0f.js"><link rel="prefetch" href="/assets/js/117.0b17f3a7.js"><link rel="prefetch" href="/assets/js/118.597baf7a.js"><link rel="prefetch" href="/assets/js/119.01c9469e.js"><link rel="prefetch" href="/assets/js/12.990b0034.js"><link rel="prefetch" href="/assets/js/120.54b6f0c8.js"><link rel="prefetch" href="/assets/js/121.40fd7b86.js"><link rel="prefetch" href="/assets/js/122.b95492bf.js"><link rel="prefetch" href="/assets/js/123.f6a2b967.js"><link rel="prefetch" href="/assets/js/124.e9e9aaee.js"><link rel="prefetch" href="/assets/js/125.f5231455.js"><link rel="prefetch" href="/assets/js/126.8085cff2.js"><link rel="prefetch" href="/assets/js/127.31fcf994.js"><link rel="prefetch" href="/assets/js/128.cf449057.js"><link rel="prefetch" href="/assets/js/129.055f3f21.js"><link rel="prefetch" href="/assets/js/13.949f696e.js"><link rel="prefetch" href="/assets/js/130.980495f1.js"><link rel="prefetch" href="/assets/js/131.e8af7eb0.js"><link rel="prefetch" href="/assets/js/132.b27be71a.js"><link rel="prefetch" href="/assets/js/133.9a8a3311.js"><link rel="prefetch" href="/assets/js/134.5214de4f.js"><link rel="prefetch" href="/assets/js/135.1ac14aeb.js"><link rel="prefetch" href="/assets/js/136.d771bdb3.js"><link rel="prefetch" href="/assets/js/137.892d4f34.js"><link rel="prefetch" href="/assets/js/138.16229fa9.js"><link rel="prefetch" href="/assets/js/139.463d947f.js"><link rel="prefetch" href="/assets/js/14.95c4c1a7.js"><link rel="prefetch" href="/assets/js/140.be6a4e72.js"><link rel="prefetch" href="/assets/js/141.356b87c8.js"><link rel="prefetch" href="/assets/js/142.3e5779f2.js"><link rel="prefetch" href="/assets/js/143.639105ba.js"><link rel="prefetch" href="/assets/js/144.8d10b936.js"><link rel="prefetch" href="/assets/js/145.e8322ce2.js"><link rel="prefetch" href="/assets/js/146.611e0af5.js"><link rel="prefetch" href="/assets/js/147.70111f30.js"><link rel="prefetch" href="/assets/js/148.0784f013.js"><link rel="prefetch" href="/assets/js/149.774ee803.js"><link rel="prefetch" href="/assets/js/15.58604908.js"><link rel="prefetch" href="/assets/js/150.2e50398d.js"><link rel="prefetch" href="/assets/js/151.fb55f581.js"><link rel="prefetch" href="/assets/js/152.4f25b604.js"><link rel="prefetch" href="/assets/js/153.ec0ec044.js"><link rel="prefetch" href="/assets/js/154.94973608.js"><link rel="prefetch" href="/assets/js/155.55db0fd5.js"><link rel="prefetch" href="/assets/js/156.502497ad.js"><link rel="prefetch" href="/assets/js/157.98016149.js"><link rel="prefetch" href="/assets/js/158.0d3314fb.js"><link rel="prefetch" href="/assets/js/159.e3f5a5b4.js"><link rel="prefetch" href="/assets/js/16.6fda8662.js"><link rel="prefetch" href="/assets/js/160.1df2bfd1.js"><link rel="prefetch" href="/assets/js/161.7a0af903.js"><link rel="prefetch" href="/assets/js/162.c21246ed.js"><link rel="prefetch" href="/assets/js/163.533edd80.js"><link rel="prefetch" href="/assets/js/164.46c6b565.js"><link rel="prefetch" href="/assets/js/165.f80ba188.js"><link rel="prefetch" href="/assets/js/166.5ac648fc.js"><link rel="prefetch" href="/assets/js/167.48768ec6.js"><link rel="prefetch" href="/assets/js/168.7df5587d.js"><link rel="prefetch" href="/assets/js/169.95e77dc8.js"><link rel="prefetch" href="/assets/js/17.9181c245.js"><link rel="prefetch" href="/assets/js/170.6045c5e8.js"><link rel="prefetch" href="/assets/js/171.92569791.js"><link rel="prefetch" href="/assets/js/172.f92fb957.js"><link rel="prefetch" href="/assets/js/173.28fab830.js"><link rel="prefetch" href="/assets/js/174.923888c0.js"><link rel="prefetch" href="/assets/js/175.5ed14239.js"><link rel="prefetch" href="/assets/js/176.c6873862.js"><link rel="prefetch" href="/assets/js/177.36e6d6f3.js"><link rel="prefetch" href="/assets/js/178.1d7e88ef.js"><link rel="prefetch" href="/assets/js/179.0acfe265.js"><link rel="prefetch" href="/assets/js/18.7f572ba6.js"><link rel="prefetch" href="/assets/js/180.ff87c21e.js"><link rel="prefetch" href="/assets/js/181.ab54b1c9.js"><link rel="prefetch" href="/assets/js/182.9941d777.js"><link rel="prefetch" href="/assets/js/183.14a00c73.js"><link rel="prefetch" href="/assets/js/184.1e955ed3.js"><link rel="prefetch" href="/assets/js/185.7e14260e.js"><link rel="prefetch" href="/assets/js/186.a3d95322.js"><link rel="prefetch" href="/assets/js/187.5292d201.js"><link rel="prefetch" href="/assets/js/188.680e5514.js"><link rel="prefetch" href="/assets/js/189.0572db25.js"><link rel="prefetch" href="/assets/js/19.5e1e2d25.js"><link rel="prefetch" href="/assets/js/190.92aba315.js"><link rel="prefetch" href="/assets/js/191.af17cf99.js"><link rel="prefetch" href="/assets/js/192.c09e272d.js"><link rel="prefetch" href="/assets/js/193.8320d583.js"><link rel="prefetch" href="/assets/js/194.c8849780.js"><link rel="prefetch" href="/assets/js/195.f7f005a0.js"><link rel="prefetch" href="/assets/js/196.30c9e918.js"><link rel="prefetch" href="/assets/js/197.3ad1634b.js"><link rel="prefetch" href="/assets/js/198.bd7d2f1f.js"><link rel="prefetch" href="/assets/js/199.d8eba117.js"><link rel="prefetch" href="/assets/js/20.c99f5141.js"><link rel="prefetch" href="/assets/js/200.6a3880cf.js"><link rel="prefetch" href="/assets/js/201.9fb4a7f0.js"><link rel="prefetch" href="/assets/js/202.3f1c6ca1.js"><link rel="prefetch" href="/assets/js/203.eed88e22.js"><link rel="prefetch" href="/assets/js/204.4df4d1ee.js"><link rel="prefetch" href="/assets/js/205.8a2954f6.js"><link rel="prefetch" href="/assets/js/206.8face9f1.js"><link rel="prefetch" href="/assets/js/207.856d7df9.js"><link rel="prefetch" href="/assets/js/208.0ce7808f.js"><link rel="prefetch" href="/assets/js/209.83e28cd8.js"><link rel="prefetch" href="/assets/js/21.d9bb9fc7.js"><link rel="prefetch" href="/assets/js/210.a7865495.js"><link rel="prefetch" href="/assets/js/211.68d502db.js"><link rel="prefetch" href="/assets/js/212.7d5fc44f.js"><link rel="prefetch" href="/assets/js/213.177360db.js"><link rel="prefetch" href="/assets/js/214.c20b8b61.js"><link rel="prefetch" href="/assets/js/215.9263fc6e.js"><link rel="prefetch" href="/assets/js/216.94654946.js"><link rel="prefetch" href="/assets/js/217.09b6f5f2.js"><link rel="prefetch" href="/assets/js/218.d65861ea.js"><link rel="prefetch" href="/assets/js/219.ad83f77b.js"><link rel="prefetch" href="/assets/js/22.fd871b20.js"><link rel="prefetch" href="/assets/js/220.f5d41586.js"><link rel="prefetch" href="/assets/js/23.c7c36b09.js"><link rel="prefetch" href="/assets/js/24.c75a1742.js"><link rel="prefetch" href="/assets/js/25.b899703c.js"><link rel="prefetch" href="/assets/js/26.c42f245b.js"><link rel="prefetch" href="/assets/js/27.88ef9fb0.js"><link rel="prefetch" href="/assets/js/28.90bfb794.js"><link rel="prefetch" href="/assets/js/29.71f58aa6.js"><link rel="prefetch" href="/assets/js/3.87503eb9.js"><link rel="prefetch" href="/assets/js/30.58f8a295.js"><link rel="prefetch" href="/assets/js/31.2c553dcd.js"><link rel="prefetch" href="/assets/js/32.3831f217.js"><link rel="prefetch" href="/assets/js/33.75d118ed.js"><link rel="prefetch" href="/assets/js/34.981a2a23.js"><link rel="prefetch" href="/assets/js/35.89582efb.js"><link rel="prefetch" href="/assets/js/36.f084d6d6.js"><link rel="prefetch" href="/assets/js/37.05b78a2e.js"><link rel="prefetch" href="/assets/js/38.7af5567b.js"><link rel="prefetch" href="/assets/js/39.c6eac1f4.js"><link rel="prefetch" href="/assets/js/4.e97d7685.js"><link rel="prefetch" href="/assets/js/40.d0b5b13f.js"><link rel="prefetch" href="/assets/js/41.061065b8.js"><link rel="prefetch" href="/assets/js/42.33e27768.js"><link rel="prefetch" href="/assets/js/43.044102be.js"><link rel="prefetch" href="/assets/js/44.f128741e.js"><link rel="prefetch" href="/assets/js/45.8b87c1e9.js"><link rel="prefetch" href="/assets/js/46.1f562f3b.js"><link rel="prefetch" href="/assets/js/47.33172e3b.js"><link rel="prefetch" href="/assets/js/48.0e90c1bc.js"><link rel="prefetch" href="/assets/js/49.c6008c31.js"><link rel="prefetch" href="/assets/js/5.750356d4.js"><link rel="prefetch" href="/assets/js/50.e19e3f49.js"><link rel="prefetch" href="/assets/js/51.c50c079d.js"><link rel="prefetch" href="/assets/js/52.354a9e0a.js"><link rel="prefetch" href="/assets/js/53.2daf89fa.js"><link rel="prefetch" href="/assets/js/54.6a9d3ea7.js"><link rel="prefetch" href="/assets/js/55.a9198cf5.js"><link rel="prefetch" href="/assets/js/56.a8ca95c2.js"><link rel="prefetch" href="/assets/js/57.4ad09579.js"><link rel="prefetch" href="/assets/js/58.99c7eafc.js"><link rel="prefetch" href="/assets/js/59.b60f2713.js"><link rel="prefetch" href="/assets/js/6.81342f3d.js"><link rel="prefetch" href="/assets/js/60.9b1e2d34.js"><link rel="prefetch" href="/assets/js/61.11744eb1.js"><link rel="prefetch" href="/assets/js/62.d107e205.js"><link rel="prefetch" href="/assets/js/63.9620e0de.js"><link rel="prefetch" href="/assets/js/64.b7844b50.js"><link rel="prefetch" href="/assets/js/65.2c271ce0.js"><link rel="prefetch" href="/assets/js/66.0002d576.js"><link rel="prefetch" href="/assets/js/67.b2b7cb20.js"><link rel="prefetch" href="/assets/js/68.0670f053.js"><link rel="prefetch" href="/assets/js/69.709b375d.js"><link rel="prefetch" href="/assets/js/7.e1569b39.js"><link rel="prefetch" href="/assets/js/70.5cecff6c.js"><link rel="prefetch" href="/assets/js/71.e99b8bee.js"><link rel="prefetch" href="/assets/js/72.9c412e7e.js"><link rel="prefetch" href="/assets/js/73.bc7a249f.js"><link rel="prefetch" href="/assets/js/74.d8129898.js"><link rel="prefetch" href="/assets/js/75.f3f2a802.js"><link rel="prefetch" href="/assets/js/76.f52eeb42.js"><link rel="prefetch" href="/assets/js/77.ba57412d.js"><link rel="prefetch" href="/assets/js/78.e1fd6d13.js"><link rel="prefetch" href="/assets/js/8.0047e591.js"><link rel="prefetch" href="/assets/js/80.bb98c935.js"><link rel="prefetch" href="/assets/js/81.e01b0b7d.js"><link rel="prefetch" href="/assets/js/82.08e1a9a2.js"><link rel="prefetch" href="/assets/js/83.b0493711.js"><link rel="prefetch" href="/assets/js/84.d8e6189a.js"><link rel="prefetch" href="/assets/js/85.869f2313.js"><link rel="prefetch" href="/assets/js/86.98ce6533.js"><link rel="prefetch" href="/assets/js/87.4031c5ae.js"><link rel="prefetch" href="/assets/js/88.bfb66255.js"><link rel="prefetch" href="/assets/js/89.8e98c18f.js"><link rel="prefetch" href="/assets/js/9.7034b8a6.js"><link rel="prefetch" href="/assets/js/90.b7b403f7.js"><link rel="prefetch" href="/assets/js/91.c21a0fac.js"><link rel="prefetch" href="/assets/js/92.9bf8a703.js"><link rel="prefetch" href="/assets/js/93.36ba76ee.js"><link rel="prefetch" href="/assets/js/94.ceaf9c54.js"><link rel="prefetch" href="/assets/js/95.820433ee.js"><link rel="prefetch" href="/assets/js/96.b3631136.js"><link rel="prefetch" href="/assets/js/97.14f5b52b.js"><link rel="prefetch" href="/assets/js/98.22bc7838.js"><link rel="prefetch" href="/assets/js/99.58c52c1f.js">
    <link rel="stylesheet" href="/assets/css/0.styles.715b4171.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">📖Documents</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow down"></span></button> <button type="button" aria-label="⚡系列文章" class="mobile-dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow down"></span></button> <button type="button" aria-label="⚡系列文章" class="mobile-dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>网络请求</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/network-request/http.html" class="sidebar-link">HTTP协议</a></li><li><a href="/python/network-request/urllib.html" class="sidebar-link">urllib库</a></li><li><a href="/python/network-request/requests.html" class="sidebar-link">requests库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据提取</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-extraction/xpath.html" class="sidebar-link">XPath语法</a></li><li><a href="/python/data-extraction/lxml.html" class="sidebar-link">lxml库</a></li><li><a href="/python/data-extraction/beautifulsoup.html" class="sidebar-link">BeautifulSoup库</a></li><li><a href="/python/data-extraction/regex.html" class="sidebar-link">Python中的正则表达式</a></li><li><a href="/python/data-extraction/python-re.html" class="sidebar-link">re模块</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据存储</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-storage/json.html" class="sidebar-link">json文件处理</a></li><li><a href="/python/data-storage/csv.html" class="sidebar-link">csv文件处理</a></li><li><a href="/python/data-storage/pymysql.html" class="sidebar-link">Python操作MySQL数据库</a></li><li><a href="/python/data-storage/mongodb.html" class="sidebar-link">Python操作MongoDB数据库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫进阶</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/multithreading.html" class="sidebar-link">多线程爬虫</a></li><li><a href="/python/spider/selenium.html" class="sidebar-link">动态网页爬虫</a></li><li><a href="/python/spider/tesseract.html" class="sidebar-link">图形验证码识别</a></li><li><a href="/python/spider/scrapy.html" aria-current="page" class="active sidebar-link">Scrapy框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架介绍" class="sidebar-link">Scrapy框架介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架模块功能" class="sidebar-link">Scrapy框架模块功能</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy安装和文档" class="sidebar-link">Scrapy安装和文档</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy快速入门" class="sidebar-link">Scrapy快速入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建项目" class="sidebar-link">创建项目</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#目录结构介绍" class="sidebar-link">目录结构介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#使用scrapy框架爬取糗事百科段子例子" class="sidebar-link">使用Scrapy框架爬取糗事百科段子例子</a></li></ul></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#jsonitemexporter和jsonlinesitemexporter" class="sidebar-link">JsonItemExporter和JsonLinesItemExporter</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy爬虫注意事项" class="sidebar-link">Scrapy爬虫注意事项</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#crawlspider" class="sidebar-link">CrawlSpider</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建crawlspider爬虫" class="sidebar-link">创建CrawlSpider爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#linkextractors链接提取器" class="sidebar-link">LinkExtractors链接提取器</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#rule规则类" class="sidebar-link">Rule规则类</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy-shell" class="sidebar-link">Scrapy Shell</a></li></ul></li><li><a href="/python/spider/scrapy-redis.html" class="sidebar-link">Scrapy-Redis分布式爬虫</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="scrapy框架"><a href="#scrapy框架" class="header-anchor">#</a> Scrapy框架</h1> <h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="header-anchor">#</a> Scrapy框架介绍</h2> <p>写一个爬虫，需要做很多的事情，比如：发送网络请求、数据解析、数据存储、反反爬虫机制(ip代理，设置请求头等)、异步请求等等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此scrapy把一些基础的东西都封装好了，在scrapy框架上开发爬虫可以变得更加的高效，爬取效率和开发效率得到提升。</p> <h2 id="scrapy框架模块功能"><a href="#scrapy框架模块功能" class="header-anchor">#</a> Scrapy框架模块功能</h2> <ul><li>Scrapy Engine（引擎）：Scrapy框架的核心部分。负责在Spider和ItemPipeline、Downloader、Scheduler中间通信、传递数据等。</li> <li>Spider（爬虫）：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li> <li>Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li> <li>Downloader（下载器）：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li> <li>Item Pipeline（管道）：负责将Spider（爬虫）传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li> <li>Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件。</li> <li>Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件。</li></ul> <h2 id="scrapy安装和文档"><a href="#scrapy安装和文档" class="header-anchor">#</a> Scrapy安装和文档</h2> <ul><li>安装：通过 <code>pip install scrapy</code> 即可安装。
<ul><li>在ubuntu上安装scrapy之前，需要先安装以下依赖：<code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过 <code>pip install scrapy</code> 安装。</li> <li>如果在windows系统下，提示这个错误ModuleNotFoundError: No module named 'win32api'，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li></ul></li> <li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener noreferrer">http://doc.scrapy.org/en/latest<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener noreferrer">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="scrapy快速入门"><a href="#scrapy快速入门" class="header-anchor">#</a> Scrapy快速入门</h2> <h3 id="创建项目"><a href="#创建项目" class="header-anchor">#</a> 创建项目</h3> <p>要使用Scrapy框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p> <p><code>scrapy startproject [项目名称]</code></p> <h3 id="目录结构介绍"><a href="#目录结构介绍" class="header-anchor">#</a> 目录结构介绍</h3> <ul><li>items.py：用来存放爬虫爬取下来数据的模型。</li> <li>middlewares.py：用来存放各种中间件的文件。</li> <li>pipelines.py：用来将items的模型存储到本地磁盘中。</li> <li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li> <li>scrapy.cfg：项目的配置文件。</li> <li>spiders包：以后所有的爬虫，都是存放到这个里面。</li></ul> <h3 id="使用scrapy框架爬取糗事百科段子例子"><a href="#使用scrapy框架爬取糗事百科段子例子" class="header-anchor">#</a> 使用Scrapy框架爬取糗事百科段子例子</h3> <h4 id="使用命令创建一个爬虫"><a href="#使用命令创建一个爬虫" class="header-anchor">#</a> 使用命令创建一个爬虫</h4> <p><code>scrapy gensipder qsbk &quot;qiushibaike.com&quot;</code></p> <p>创建了一个名字叫做 qsbk 的爬虫，并且能爬取的网页只会限制在 qiushibaike.com 这个域名下。</p> <h4 id="爬虫代码解析"><a href="#爬虫代码解析" class="header-anchor">#</a> 爬虫代码解析</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。</p> <p>要创建一个Spider，那么必须自定义一个类，继承自scrapy.Spider，然后在这个类中定义三个属性和一个方法。</p> <ul><li>name：这个爬虫的名字，名字必须是唯一的。</li> <li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li> <li>start_urls：爬虫从这个变量中的url开始。</li> <li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个parse方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li></ul> <h4 id="修改settings-py代码"><a href="#修改settings-py代码" class="header-anchor">#</a> 修改settings.py代码</h4> <p>在做一个爬虫之前，一定要记得修改setttings.py中的设置。两个地方是强烈建议设置的。</p> <ul><li>ROBOTSTXT_OBEY设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li> <li>DEFAULT_REQUEST_HEADERS添加User-Agent。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li></ul> <h4 id="完成的爬虫代码"><a href="#完成的爬虫代码" class="header-anchor">#</a> 完成的爬虫代码</h4> <h5 id="爬虫部分代码"><a href="#爬虫部分代码" class="header-anchor">#</a> 爬虫部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>response<span class="token punctuation">.</span>html <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>unified <span class="token keyword">import</span> SelectorList
<span class="token keyword">from</span> qsbk<span class="token punctuation">.</span>items <span class="token keyword">import</span> QsbkItem

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk_spider'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/page/1/'</span><span class="token punctuation">]</span>
    base_domain <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duanziDivs <span class="token operator">=</span> contentLeft <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//div[@id='content-left']/div&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> duanzidiv <span class="token keyword">in</span> duanziDivs<span class="token punctuation">:</span>
            author <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//h2/text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class='content']//text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># duanzi = {&quot;author&quot;:author,&quot;content&quot;:content}</span>
            <span class="token comment"># yield duanzi</span>

            item <span class="token operator">=</span> QsbkItem<span class="token punctuation">(</span>author<span class="token operator">=</span>author<span class="token punctuation">,</span>content<span class="token operator">=</span>content<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item
        next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ul[@class='pagination']/li[last()]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> next_url<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_domain <span class="token operator">+</span> next_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h5 id="items-py部分代码"><a href="#items-py部分代码" class="header-anchor">#</a> items.py部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h5 id="pipeline部分代码"><a href="#pipeline部分代码" class="header-anchor">#</a> pipeline部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 方式1</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item_json <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>item_json<span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式2</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式3</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonLinesItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><h4 id="运行scrapy项目"><a href="#运行scrapy项目" class="header-anchor">#</a> 运行scrapy项目</h4> <p>运行scrapy项目。需要在终端，进入项目所在的路径，然后 <code>scrapy crawl [爬虫名字]</code> 即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做 start.py，然后在这个文件中填入以下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl qsbk&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="jsonitemexporter和jsonlinesitemexporter"><a href="#jsonitemexporter和jsonlinesitemexporter" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExporter</h2> <ul><li>保存json数据的时候，可以使用这两个类，让操作变得更简单</li> <li><code>JsonItemExporter</code>：每次把数据添加到内存中，最后统一写入磁盘，存储的数据是一个满足json规则的数据，数据量比较大，比较耗内存</li> <li><code>JsonLinesItemExporter</code>：每次调用<code>export_item</code>的时候把这个item存储到磁盘，每一个字典是一行，整个文件不是一个满足json格式的文件，每次处理初级的时候直接存储到硬盘，不耗内存，数据比较安全</li></ul> <h2 id="scrapy爬虫注意事项"><a href="#scrapy爬虫注意事项" class="header-anchor">#</a> Scrapy爬虫注意事项</h2> <ul><li>response 是一个<code>from scrapy.http.response.html.HtmlResponse</code>对象，可以执行<code>xpath</code>和<code>css</code>语法提取数据</li> <li>提取出来的数据是一个<code>Selector</code>或者<code>SelectorList</code>对象，如果想要获取其中的字符串，应该执行<code>getall</code>或者<code>get</code>方法</li> <li>getall方法：获取<code>Selector</code>中所有文本，返回的是一个列表</li> <li>get方法：获取的是<code>Selector</code>中的第一个文本，返回的是str类型</li> <li>如果数据解析回来要传给pipelines处理，可以使用<code>yield</code>来返回，或者是添加所有的item，统一使用<code>return</code>返回</li> <li>item：在<code>item.py</code>中定义好模型，不要使用字典</li> <li>pipelines：这个是专门一从来保存数据的，其中有三个方法是会被经常用到的。要激活pipelines，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code> <ul><li><code>open_spider</code>：当爬虫被打开的时候执行</li> <li><code>process_item</code>：当爬虫有item传过来的时候会被调用</li> <li><code>close_spider</code>：当爬虫关闭的时候被调用</li></ul></li></ul> <h2 id="crawlspider"><a href="#crawlspider" class="header-anchor">#</a> CrawlSpider</h2> <p>在糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过CrawlSpider来帮我们完成了。CrawlSpider继承自Spider，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的yield Request。</p> <h2 id="创建crawlspider爬虫"><a href="#创建crawlspider爬虫" class="header-anchor">#</a> 创建CrawlSpider爬虫</h2> <p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建CrawlSpider爬虫，那么应该通过以下命令创建：</p> <p><code>scrapy genspider -c crawl [爬虫名字] [域名]</code></p> <h2 id="linkextractors链接提取器"><a href="#linkextractors链接提取器" class="header-anchor">#</a> LinkExtractors链接提取器</h2> <p>使用LinkExtractors可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给LinkExtractors，他会在所有爬的页面中找到满足规则的url，实现自动的爬取。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_extensions <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tags <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    attrs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    canonicalize <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    unique <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    process_value <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li> <li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li> <li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li> <li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li> <li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li></ul> <h2 id="rule规则类"><a href="#rule规则类" class="header-anchor">#</a> Rule规则类</h2> <p>定义爬虫的规则类。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>Rule<span class="token punctuation">(</span>
    link_extractor<span class="token punctuation">,</span>
    callback <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    cb_kwargs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    follow <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_links <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_request <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>link_extractor：一个LinkExtractor对象，用于定义爬取规则。</li> <li>callback：满足这个规则的url，应该要执行哪个回调函数。因为CrawlSpider使用了parse作为回调函数，因此不要覆盖parse作为回调函数自己的回调函数。</li> <li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li> <li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li></ul> <h2 id="scrapy-shell"><a href="#scrapy-shell" class="header-anchor">#</a> Scrapy Shell</h2> <p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为scrapy是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此Scrapy提供了一个shell，用来方便的测试规则</p> <p>打开cmd终端，进入到Scrapy项目所在的目录，然后进入到scrapy框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的parse方法中一样使用了。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/meowv/docs/edit/master//python/spider/scrapy.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">6 days ago</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/tesseract.html" class="prev">
        图形验证码识别
      </a></span> <span class="next"><a href="/python/spider/scrapy-redis.html">
        Scrapy-Redis分布式爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.75313780.js" defer></script><script src="/assets/js/2.2c885d95.js" defer></script><script src="/assets/js/79.102a7fb7.js" defer></script>
  </body>
</html>
