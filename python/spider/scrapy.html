<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy框架 | 📖Documents</title>
    <meta name="generator" content="VuePress 1.5.3">
    <script>
        var _mtac = {"senseQuery":1};
        (function() {
            var mta = document.createElement("script");
            mta.src = "//pingjs.qq.com/h5/stats.js?v2.0.4";
            mta.setAttribute("name", "MTAH5");
            mta.setAttribute("sid", "500727760");
            mta.setAttribute("cid", "500727761");
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(mta, s);
        })();
        </script>
    <meta name="description" content="This is a personal document library for development work">
    <link rel="preload" href="/assets/css/0.styles.7cd537df.css" as="style"><link rel="preload" href="/assets/js/app.234db02d.js" as="script"><link rel="preload" href="/assets/js/2.e67a6740.js" as="script"><link rel="preload" href="/assets/js/74.8ef9fff5.js" as="script"><link rel="prefetch" href="/assets/js/10.54e49911.js"><link rel="prefetch" href="/assets/js/100.49711292.js"><link rel="prefetch" href="/assets/js/101.67dfdff7.js"><link rel="prefetch" href="/assets/js/102.b94bb8ca.js"><link rel="prefetch" href="/assets/js/103.0f247359.js"><link rel="prefetch" href="/assets/js/104.eae47610.js"><link rel="prefetch" href="/assets/js/105.e1ddd365.js"><link rel="prefetch" href="/assets/js/106.82efb313.js"><link rel="prefetch" href="/assets/js/107.2118e50f.js"><link rel="prefetch" href="/assets/js/108.35ad8f98.js"><link rel="prefetch" href="/assets/js/109.6951ed80.js"><link rel="prefetch" href="/assets/js/11.e1a3c88f.js"><link rel="prefetch" href="/assets/js/110.fd87128d.js"><link rel="prefetch" href="/assets/js/111.5c9a54a6.js"><link rel="prefetch" href="/assets/js/112.72b65210.js"><link rel="prefetch" href="/assets/js/113.a749c725.js"><link rel="prefetch" href="/assets/js/114.34238d2f.js"><link rel="prefetch" href="/assets/js/115.54402457.js"><link rel="prefetch" href="/assets/js/116.f953cd51.js"><link rel="prefetch" href="/assets/js/117.2362d5e0.js"><link rel="prefetch" href="/assets/js/118.30014409.js"><link rel="prefetch" href="/assets/js/119.a9a2bd39.js"><link rel="prefetch" href="/assets/js/12.e29e4cf7.js"><link rel="prefetch" href="/assets/js/120.682f8ec0.js"><link rel="prefetch" href="/assets/js/121.2c9e1952.js"><link rel="prefetch" href="/assets/js/122.505d54bf.js"><link rel="prefetch" href="/assets/js/123.49ae5780.js"><link rel="prefetch" href="/assets/js/124.d4fe5d5f.js"><link rel="prefetch" href="/assets/js/125.3f7d1ac8.js"><link rel="prefetch" href="/assets/js/126.141d44d4.js"><link rel="prefetch" href="/assets/js/127.224161e6.js"><link rel="prefetch" href="/assets/js/128.cada4294.js"><link rel="prefetch" href="/assets/js/129.193e58ee.js"><link rel="prefetch" href="/assets/js/13.501f7ea1.js"><link rel="prefetch" href="/assets/js/130.38eb5994.js"><link rel="prefetch" href="/assets/js/131.8ad118fc.js"><link rel="prefetch" href="/assets/js/132.d43ab3e0.js"><link rel="prefetch" href="/assets/js/133.5c8e893a.js"><link rel="prefetch" href="/assets/js/134.edaacf4a.js"><link rel="prefetch" href="/assets/js/135.677d9e8b.js"><link rel="prefetch" href="/assets/js/136.9e14869c.js"><link rel="prefetch" href="/assets/js/137.a4b764e9.js"><link rel="prefetch" href="/assets/js/138.46e412e6.js"><link rel="prefetch" href="/assets/js/139.634f5286.js"><link rel="prefetch" href="/assets/js/14.7d3689c0.js"><link rel="prefetch" href="/assets/js/140.ad09c772.js"><link rel="prefetch" href="/assets/js/141.ad382908.js"><link rel="prefetch" href="/assets/js/142.f45db249.js"><link rel="prefetch" href="/assets/js/143.6fb8368e.js"><link rel="prefetch" href="/assets/js/144.6db1b2ac.js"><link rel="prefetch" href="/assets/js/145.0758beb2.js"><link rel="prefetch" href="/assets/js/146.2831e565.js"><link rel="prefetch" href="/assets/js/147.326d0cf4.js"><link rel="prefetch" href="/assets/js/148.0c4ac5a9.js"><link rel="prefetch" href="/assets/js/149.84908dff.js"><link rel="prefetch" href="/assets/js/15.bf1bd191.js"><link rel="prefetch" href="/assets/js/150.c7f3d27b.js"><link rel="prefetch" href="/assets/js/151.cf175076.js"><link rel="prefetch" href="/assets/js/152.866af30a.js"><link rel="prefetch" href="/assets/js/153.4ea13409.js"><link rel="prefetch" href="/assets/js/154.653c1efc.js"><link rel="prefetch" href="/assets/js/155.f438a1b9.js"><link rel="prefetch" href="/assets/js/156.6a8f6e65.js"><link rel="prefetch" href="/assets/js/157.44a54438.js"><link rel="prefetch" href="/assets/js/158.003ea5ed.js"><link rel="prefetch" href="/assets/js/159.134561dd.js"><link rel="prefetch" href="/assets/js/16.0f907a3d.js"><link rel="prefetch" href="/assets/js/160.b89c0295.js"><link rel="prefetch" href="/assets/js/161.cd95a80d.js"><link rel="prefetch" href="/assets/js/162.3250ed1d.js"><link rel="prefetch" href="/assets/js/163.8cba538a.js"><link rel="prefetch" href="/assets/js/164.44a36804.js"><link rel="prefetch" href="/assets/js/165.3c96363c.js"><link rel="prefetch" href="/assets/js/166.75a5d72b.js"><link rel="prefetch" href="/assets/js/167.a10ce91e.js"><link rel="prefetch" href="/assets/js/168.36413d61.js"><link rel="prefetch" href="/assets/js/169.768b94c0.js"><link rel="prefetch" href="/assets/js/17.577f168b.js"><link rel="prefetch" href="/assets/js/170.9703a900.js"><link rel="prefetch" href="/assets/js/171.f6a504f8.js"><link rel="prefetch" href="/assets/js/172.06a00534.js"><link rel="prefetch" href="/assets/js/173.99f419e6.js"><link rel="prefetch" href="/assets/js/174.c734264c.js"><link rel="prefetch" href="/assets/js/175.f81520ec.js"><link rel="prefetch" href="/assets/js/176.924b9fc2.js"><link rel="prefetch" href="/assets/js/177.006b7a0e.js"><link rel="prefetch" href="/assets/js/178.27bd860a.js"><link rel="prefetch" href="/assets/js/179.09155611.js"><link rel="prefetch" href="/assets/js/18.17e182ce.js"><link rel="prefetch" href="/assets/js/180.25c09c45.js"><link rel="prefetch" href="/assets/js/181.adda20c0.js"><link rel="prefetch" href="/assets/js/182.2437747f.js"><link rel="prefetch" href="/assets/js/183.5cc1c696.js"><link rel="prefetch" href="/assets/js/184.6f0dd564.js"><link rel="prefetch" href="/assets/js/185.385312c8.js"><link rel="prefetch" href="/assets/js/186.e200052b.js"><link rel="prefetch" href="/assets/js/187.48465d01.js"><link rel="prefetch" href="/assets/js/188.89678f04.js"><link rel="prefetch" href="/assets/js/189.68c71d11.js"><link rel="prefetch" href="/assets/js/19.2c9b42ae.js"><link rel="prefetch" href="/assets/js/190.8e5a9c4f.js"><link rel="prefetch" href="/assets/js/191.933873b6.js"><link rel="prefetch" href="/assets/js/192.5b38f574.js"><link rel="prefetch" href="/assets/js/193.ee32dba3.js"><link rel="prefetch" href="/assets/js/194.168b8d74.js"><link rel="prefetch" href="/assets/js/195.3444649d.js"><link rel="prefetch" href="/assets/js/196.d95564c4.js"><link rel="prefetch" href="/assets/js/197.6dc50349.js"><link rel="prefetch" href="/assets/js/198.eb24d83a.js"><link rel="prefetch" href="/assets/js/199.5915600a.js"><link rel="prefetch" href="/assets/js/20.8f96e09e.js"><link rel="prefetch" href="/assets/js/200.508150ee.js"><link rel="prefetch" href="/assets/js/201.cb3c8242.js"><link rel="prefetch" href="/assets/js/202.019b43f6.js"><link rel="prefetch" href="/assets/js/203.8a7cee7e.js"><link rel="prefetch" href="/assets/js/204.e12af76a.js"><link rel="prefetch" href="/assets/js/205.17559294.js"><link rel="prefetch" href="/assets/js/206.7ae8a4cf.js"><link rel="prefetch" href="/assets/js/207.c873681f.js"><link rel="prefetch" href="/assets/js/208.9e07de41.js"><link rel="prefetch" href="/assets/js/209.7921371c.js"><link rel="prefetch" href="/assets/js/21.024673e9.js"><link rel="prefetch" href="/assets/js/210.d017ab60.js"><link rel="prefetch" href="/assets/js/22.913a0d30.js"><link rel="prefetch" href="/assets/js/23.829f32c0.js"><link rel="prefetch" href="/assets/js/24.add2a8cc.js"><link rel="prefetch" href="/assets/js/25.7febaf2b.js"><link rel="prefetch" href="/assets/js/26.128460c1.js"><link rel="prefetch" href="/assets/js/27.56034b8b.js"><link rel="prefetch" href="/assets/js/28.eb54bb7d.js"><link rel="prefetch" href="/assets/js/29.90fb8b29.js"><link rel="prefetch" href="/assets/js/3.27542b97.js"><link rel="prefetch" href="/assets/js/30.bf8540af.js"><link rel="prefetch" href="/assets/js/31.f17c2279.js"><link rel="prefetch" href="/assets/js/32.cc7ba61d.js"><link rel="prefetch" href="/assets/js/33.fc875fc2.js"><link rel="prefetch" href="/assets/js/34.c95e584c.js"><link rel="prefetch" href="/assets/js/35.204bab85.js"><link rel="prefetch" href="/assets/js/36.e414e99c.js"><link rel="prefetch" href="/assets/js/37.e623dab7.js"><link rel="prefetch" href="/assets/js/38.64d8b654.js"><link rel="prefetch" href="/assets/js/39.df4e93a0.js"><link rel="prefetch" href="/assets/js/4.717c2489.js"><link rel="prefetch" href="/assets/js/40.53b783a5.js"><link rel="prefetch" href="/assets/js/41.d60a9b36.js"><link rel="prefetch" href="/assets/js/42.c90769c7.js"><link rel="prefetch" href="/assets/js/43.17b2cfff.js"><link rel="prefetch" href="/assets/js/44.723497e2.js"><link rel="prefetch" href="/assets/js/45.413aba78.js"><link rel="prefetch" href="/assets/js/46.0b60e2ac.js"><link rel="prefetch" href="/assets/js/47.ed47fb0d.js"><link rel="prefetch" href="/assets/js/48.8eb1d165.js"><link rel="prefetch" href="/assets/js/49.42b1cef4.js"><link rel="prefetch" href="/assets/js/5.8dedd878.js"><link rel="prefetch" href="/assets/js/50.7b1588d5.js"><link rel="prefetch" href="/assets/js/51.8fafa745.js"><link rel="prefetch" href="/assets/js/52.8a7364dc.js"><link rel="prefetch" href="/assets/js/53.e4befdc1.js"><link rel="prefetch" href="/assets/js/54.45632769.js"><link rel="prefetch" href="/assets/js/55.edd9196f.js"><link rel="prefetch" href="/assets/js/56.1bb6a3fd.js"><link rel="prefetch" href="/assets/js/57.a51dba92.js"><link rel="prefetch" href="/assets/js/58.b092ddeb.js"><link rel="prefetch" href="/assets/js/59.a5d92d24.js"><link rel="prefetch" href="/assets/js/6.9949c8ee.js"><link rel="prefetch" href="/assets/js/60.7b86d8f8.js"><link rel="prefetch" href="/assets/js/61.29dd18f7.js"><link rel="prefetch" href="/assets/js/62.8b2d2459.js"><link rel="prefetch" href="/assets/js/63.7ad68a38.js"><link rel="prefetch" href="/assets/js/64.fa107b19.js"><link rel="prefetch" href="/assets/js/65.23f6febf.js"><link rel="prefetch" href="/assets/js/66.dd6019a0.js"><link rel="prefetch" href="/assets/js/67.84c16db2.js"><link rel="prefetch" href="/assets/js/68.f9a7b1ce.js"><link rel="prefetch" href="/assets/js/69.16ceaa3b.js"><link rel="prefetch" href="/assets/js/7.128193eb.js"><link rel="prefetch" href="/assets/js/70.76c5601a.js"><link rel="prefetch" href="/assets/js/71.b6b3280e.js"><link rel="prefetch" href="/assets/js/72.5140fc3f.js"><link rel="prefetch" href="/assets/js/73.f8ec8843.js"><link rel="prefetch" href="/assets/js/75.6650b312.js"><link rel="prefetch" href="/assets/js/76.5eafabe0.js"><link rel="prefetch" href="/assets/js/77.10fecb68.js"><link rel="prefetch" href="/assets/js/78.540bc19c.js"><link rel="prefetch" href="/assets/js/79.704e594e.js"><link rel="prefetch" href="/assets/js/8.fe47ba8d.js"><link rel="prefetch" href="/assets/js/80.b931bd05.js"><link rel="prefetch" href="/assets/js/81.0c793c1a.js"><link rel="prefetch" href="/assets/js/82.2589bf35.js"><link rel="prefetch" href="/assets/js/83.3d65669c.js"><link rel="prefetch" href="/assets/js/84.62534ef6.js"><link rel="prefetch" href="/assets/js/85.41423dba.js"><link rel="prefetch" href="/assets/js/86.63ccf121.js"><link rel="prefetch" href="/assets/js/87.6f6e5626.js"><link rel="prefetch" href="/assets/js/88.3f5039ae.js"><link rel="prefetch" href="/assets/js/89.49b1130e.js"><link rel="prefetch" href="/assets/js/9.42da0f60.js"><link rel="prefetch" href="/assets/js/90.90f1aae7.js"><link rel="prefetch" href="/assets/js/91.72782924.js"><link rel="prefetch" href="/assets/js/92.cca8a5a0.js"><link rel="prefetch" href="/assets/js/93.d9bbfa35.js"><link rel="prefetch" href="/assets/js/94.57212010.js"><link rel="prefetch" href="/assets/js/95.89c7ba09.js"><link rel="prefetch" href="/assets/js/96.d8e68dd0.js"><link rel="prefetch" href="/assets/js/97.dc4e8bd3.js"><link rel="prefetch" href="/assets/js/98.29cf1bec.js"><link rel="prefetch" href="/assets/js/99.58480bc6.js">
    <link rel="stylesheet" href="/assets/css/0.styles.7cd537df.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">📖Documents</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>网络请求</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/network-request/http.html" class="sidebar-link">HTTP协议</a></li><li><a href="/python/network-request/urllib.html" class="sidebar-link">urllib库</a></li><li><a href="/python/network-request/requests.html" class="sidebar-link">requests库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据提取</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-extraction/xpath.html" class="sidebar-link">XPath语法</a></li><li><a href="/python/data-extraction/lxml.html" class="sidebar-link">lxml库</a></li><li><a href="/python/data-extraction/beautifulsoup.html" class="sidebar-link">BeautifulSoup库</a></li><li><a href="/python/data-extraction/regex.html" class="sidebar-link">Python中的正则表达式</a></li><li><a href="/python/data-extraction/python-re.html" class="sidebar-link">re模块</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据存储</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-storage/json.html" class="sidebar-link">json文件处理</a></li><li><a href="/python/data-storage/csv.html" class="sidebar-link">csv文件处理</a></li><li><a href="/python/data-storage/pymysql.html" class="sidebar-link">Python操作MySQL数据库</a></li><li><a href="/python/data-storage/mongodb.html" class="sidebar-link">Python操作MongoDB数据库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫进阶</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/multithreading.html" class="sidebar-link">多线程爬虫</a></li><li><a href="/python/spider/selenium.html" class="sidebar-link">动态网页爬虫</a></li><li><a href="/python/spider/tesseract.html" class="sidebar-link">图形验证码识别</a></li><li><a href="/python/spider/scrapy.html" aria-current="page" class="active sidebar-link">Scrapy框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架介绍" class="sidebar-link">Scrapy框架介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架模块功能" class="sidebar-link">Scrapy框架模块功能</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy安装和文档" class="sidebar-link">Scrapy安装和文档</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy快速入门" class="sidebar-link">Scrapy快速入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建项目" class="sidebar-link">创建项目</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#目录结构介绍" class="sidebar-link">目录结构介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#使用scrapy框架爬取糗事百科段子例子" class="sidebar-link">使用Scrapy框架爬取糗事百科段子例子</a></li></ul></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#jsonitemexporter和jsonlinesitemexporter" class="sidebar-link">JsonItemExporter和JsonLinesItemExporter</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy爬虫注意事项" class="sidebar-link">Scrapy爬虫注意事项</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#crawlspider" class="sidebar-link">CrawlSpider</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建crawlspider爬虫" class="sidebar-link">创建CrawlSpider爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#linkextractors链接提取器" class="sidebar-link">LinkExtractors链接提取器</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#rule规则类" class="sidebar-link">Rule规则类</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy-shell" class="sidebar-link">Scrapy Shell</a></li></ul></li><li><a href="/python/spider/scrapy-redis.html" class="sidebar-link">Scrapy-Redis分布式爬虫</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="scrapy框架"><a href="#scrapy框架" class="header-anchor">#</a> Scrapy框架</h1> <h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="header-anchor">#</a> Scrapy框架介绍</h2> <p>写一个爬虫，需要做很多的事情，比如：发送网络请求、数据解析、数据存储、反反爬虫机制(ip代理，设置请求头等)、异步请求等等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此scrapy把一些基础的东西都封装好了，在scrapy框架上开发爬虫可以变得更加的高效，爬取效率和开发效率得到提升。</p> <h2 id="scrapy框架模块功能"><a href="#scrapy框架模块功能" class="header-anchor">#</a> Scrapy框架模块功能</h2> <ul><li>Scrapy Engine（引擎）：Scrapy框架的核心部分。负责在Spider和ItemPipeline、Downloader、Scheduler中间通信、传递数据等。</li> <li>Spider（爬虫）：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li> <li>Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li> <li>Downloader（下载器）：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li> <li>Item Pipeline（管道）：负责将Spider（爬虫）传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li> <li>Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件。</li> <li>Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件。</li></ul> <h2 id="scrapy安装和文档"><a href="#scrapy安装和文档" class="header-anchor">#</a> Scrapy安装和文档</h2> <ul><li>安装：通过 <code>pip install scrapy</code> 即可安装。
<ul><li>在ubuntu上安装scrapy之前，需要先安装以下依赖：<code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过 <code>pip install scrapy</code> 安装。</li> <li>如果在windows系统下，提示这个错误ModuleNotFoundError: No module named 'win32api'，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li></ul></li> <li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener noreferrer">http://doc.scrapy.org/en/latest<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener noreferrer">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="scrapy快速入门"><a href="#scrapy快速入门" class="header-anchor">#</a> Scrapy快速入门</h2> <h3 id="创建项目"><a href="#创建项目" class="header-anchor">#</a> 创建项目</h3> <p>要使用Scrapy框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p> <p><code>scrapy startproject [项目名称]</code></p> <h3 id="目录结构介绍"><a href="#目录结构介绍" class="header-anchor">#</a> 目录结构介绍</h3> <ul><li>items.py：用来存放爬虫爬取下来数据的模型。</li> <li>middlewares.py：用来存放各种中间件的文件。</li> <li>pipelines.py：用来将items的模型存储到本地磁盘中。</li> <li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li> <li>scrapy.cfg：项目的配置文件。</li> <li>spiders包：以后所有的爬虫，都是存放到这个里面。</li></ul> <h3 id="使用scrapy框架爬取糗事百科段子例子"><a href="#使用scrapy框架爬取糗事百科段子例子" class="header-anchor">#</a> 使用Scrapy框架爬取糗事百科段子例子</h3> <h4 id="使用命令创建一个爬虫"><a href="#使用命令创建一个爬虫" class="header-anchor">#</a> 使用命令创建一个爬虫</h4> <p><code>scrapy gensipder qsbk &quot;qiushibaike.com&quot;</code></p> <p>创建了一个名字叫做 qsbk 的爬虫，并且能爬取的网页只会限制在 qiushibaike.com 这个域名下。</p> <h4 id="爬虫代码解析"><a href="#爬虫代码解析" class="header-anchor">#</a> 爬虫代码解析</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。</p> <p>要创建一个Spider，那么必须自定义一个类，继承自scrapy.Spider，然后在这个类中定义三个属性和一个方法。</p> <ul><li>name：这个爬虫的名字，名字必须是唯一的。</li> <li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li> <li>start_urls：爬虫从这个变量中的url开始。</li> <li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个parse方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li></ul> <h4 id="修改settings-py代码"><a href="#修改settings-py代码" class="header-anchor">#</a> 修改settings.py代码</h4> <p>在做一个爬虫之前，一定要记得修改setttings.py中的设置。两个地方是强烈建议设置的。</p> <ul><li>ROBOTSTXT_OBEY设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li> <li>DEFAULT_REQUEST_HEADERS添加User-Agent。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li></ul> <h4 id="完成的爬虫代码"><a href="#完成的爬虫代码" class="header-anchor">#</a> 完成的爬虫代码</h4> <h5 id="爬虫部分代码"><a href="#爬虫部分代码" class="header-anchor">#</a> 爬虫部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>response<span class="token punctuation">.</span>html <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>unified <span class="token keyword">import</span> SelectorList
<span class="token keyword">from</span> qsbk<span class="token punctuation">.</span>items <span class="token keyword">import</span> QsbkItem

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk_spider'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/page/1/'</span><span class="token punctuation">]</span>
    base_domain <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duanziDivs <span class="token operator">=</span> contentLeft <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//div[@id='content-left']/div&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> duanzidiv <span class="token keyword">in</span> duanziDivs<span class="token punctuation">:</span>
            author <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//h2/text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class='content']//text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># duanzi = {&quot;author&quot;:author,&quot;content&quot;:content}</span>
            <span class="token comment"># yield duanzi</span>

            item <span class="token operator">=</span> QsbkItem<span class="token punctuation">(</span>author<span class="token operator">=</span>author<span class="token punctuation">,</span>content<span class="token operator">=</span>content<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item
        next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ul[@class='pagination']/li[last()]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> next_url<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_domain <span class="token operator">+</span> next_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h5 id="items-py部分代码"><a href="#items-py部分代码" class="header-anchor">#</a> items.py部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h5 id="pipeline部分代码"><a href="#pipeline部分代码" class="header-anchor">#</a> pipeline部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 方式1</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item_json <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>item_json<span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式2</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式3</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonLinesItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><h4 id="运行scrapy项目"><a href="#运行scrapy项目" class="header-anchor">#</a> 运行scrapy项目</h4> <p>运行scrapy项目。需要在终端，进入项目所在的路径，然后 <code>scrapy crawl [爬虫名字]</code> 即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做 start.py，然后在这个文件中填入以下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl qsbk&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="jsonitemexporter和jsonlinesitemexporter"><a href="#jsonitemexporter和jsonlinesitemexporter" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExporter</h2> <ul><li>保存json数据的时候，可以使用这两个类，让操作变得更简单</li> <li><code>JsonItemExporter</code>：每次把数据添加到内存中，最后统一写入磁盘，存储的数据是一个满足json规则的数据，数据量比较大，比较耗内存</li> <li><code>JsonLinesItemExporter</code>：每次调用<code>export_item</code>的时候把这个item存储到磁盘，每一个字典是一行，整个文件不是一个满足json格式的文件，每次处理初级的时候直接存储到硬盘，不耗内存，数据比较安全</li></ul> <h2 id="scrapy爬虫注意事项"><a href="#scrapy爬虫注意事项" class="header-anchor">#</a> Scrapy爬虫注意事项</h2> <ul><li>response 是一个<code>from scrapy.http.response.html.HtmlResponse</code>对象，可以执行<code>xpath</code>和<code>css</code>语法提取数据</li> <li>提取出来的数据是一个<code>Selector</code>或者<code>SelectorList</code>对象，如果想要获取其中的字符串，应该执行<code>getall</code>或者<code>get</code>方法</li> <li>getall方法：获取<code>Selector</code>中所有文本，返回的是一个列表</li> <li>get方法：获取的是<code>Selector</code>中的第一个文本，返回的是str类型</li> <li>如果数据解析回来要传给pipelines处理，可以使用<code>yield</code>来返回，或者是添加所有的item，统一使用<code>return</code>返回</li> <li>item：在<code>item.py</code>中定义好模型，不要使用字典</li> <li>pipelines：这个是专门一从来保存数据的，其中有三个方法是会被经常用到的。要激活pipelines，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code> <ul><li><code>open_spider</code>：当爬虫被打开的时候执行</li> <li><code>process_item</code>：当爬虫有item传过来的时候会被调用</li> <li><code>close_spider</code>：当爬虫关闭的时候被调用</li></ul></li></ul> <h2 id="crawlspider"><a href="#crawlspider" class="header-anchor">#</a> CrawlSpider</h2> <p>在糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过CrawlSpider来帮我们完成了。CrawlSpider继承自Spider，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的yield Request。</p> <h2 id="创建crawlspider爬虫"><a href="#创建crawlspider爬虫" class="header-anchor">#</a> 创建CrawlSpider爬虫</h2> <p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建CrawlSpider爬虫，那么应该通过以下命令创建：</p> <p><code>scrapy genspider -c crawl [爬虫名字] [域名]</code></p> <h2 id="linkextractors链接提取器"><a href="#linkextractors链接提取器" class="header-anchor">#</a> LinkExtractors链接提取器</h2> <p>使用LinkExtractors可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给LinkExtractors，他会在所有爬的页面中找到满足规则的url，实现自动的爬取。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_extensions <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tags <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    attrs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    canonicalize <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    unique <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    process_value <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li> <li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li> <li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li> <li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li> <li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li></ul> <h2 id="rule规则类"><a href="#rule规则类" class="header-anchor">#</a> Rule规则类</h2> <p>定义爬虫的规则类。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>Rule<span class="token punctuation">(</span>
    link_extractor<span class="token punctuation">,</span>
    callback <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    cb_kwargs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    follow <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_links <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_request <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>link_extractor：一个LinkExtractor对象，用于定义爬取规则。</li> <li>callback：满足这个规则的url，应该要执行哪个回调函数。因为CrawlSpider使用了parse作为回调函数，因此不要覆盖parse作为回调函数自己的回调函数。</li> <li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li> <li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li></ul> <h2 id="scrapy-shell"><a href="#scrapy-shell" class="header-anchor">#</a> Scrapy Shell</h2> <p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为scrapy是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此Scrapy提供了一个shell，用来方便的测试规则</p> <p>打开cmd终端，进入到Scrapy项目所在的目录，然后进入到scrapy框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的parse方法中一样使用了。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/meowv/docs/edit/master//python/spider/scrapy.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">3 days ago</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/tesseract.html" class="prev">
        图形验证码识别
      </a></span> <span class="next"><a href="/python/spider/scrapy-redis.html">
        Scrapy-Redis分布式爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.234db02d.js" defer></script><script src="/assets/js/2.e67a6740.js" defer></script><script src="/assets/js/74.8ef9fff5.js" defer></script>
  </body>
</html>
