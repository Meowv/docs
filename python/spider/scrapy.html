<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy框架 | 📖Documents</title>
    <meta name="generator" content="VuePress 1.5.3">
    <script>
        var _mtac = {"senseQuery":1};
        (function() {
            var mta = document.createElement("script");
            mta.src = "//pingjs.qq.com/h5/stats.js?v2.0.4";
            mta.setAttribute("name", "MTAH5");
            mta.setAttribute("sid", "500727760");
            mta.setAttribute("cid", "500727761");
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(mta, s);
        })();
        </script>
    <meta name="description" content="This is a personal document library for development work">
    <link rel="preload" href="/assets/css/0.styles.7cd537df.css" as="style"><link rel="preload" href="/assets/js/app.2392be18.js" as="script"><link rel="preload" href="/assets/js/2.0955582b.js" as="script"><link rel="preload" href="/assets/js/75.aecfa217.js" as="script"><link rel="prefetch" href="/assets/js/10.b62d2048.js"><link rel="prefetch" href="/assets/js/100.caf9fa34.js"><link rel="prefetch" href="/assets/js/101.5d41c5e2.js"><link rel="prefetch" href="/assets/js/102.ce3508f2.js"><link rel="prefetch" href="/assets/js/103.bb952c01.js"><link rel="prefetch" href="/assets/js/104.6598655a.js"><link rel="prefetch" href="/assets/js/105.7fdd2df5.js"><link rel="prefetch" href="/assets/js/106.0faf6ce6.js"><link rel="prefetch" href="/assets/js/107.3397e482.js"><link rel="prefetch" href="/assets/js/108.0f8ab8be.js"><link rel="prefetch" href="/assets/js/109.b2682806.js"><link rel="prefetch" href="/assets/js/11.f361689e.js"><link rel="prefetch" href="/assets/js/110.e7701bf4.js"><link rel="prefetch" href="/assets/js/111.41a85fef.js"><link rel="prefetch" href="/assets/js/112.bbf0f1a1.js"><link rel="prefetch" href="/assets/js/113.47efb297.js"><link rel="prefetch" href="/assets/js/114.a1215529.js"><link rel="prefetch" href="/assets/js/115.2ff2a0e2.js"><link rel="prefetch" href="/assets/js/116.03963141.js"><link rel="prefetch" href="/assets/js/117.4fc80680.js"><link rel="prefetch" href="/assets/js/118.978589ff.js"><link rel="prefetch" href="/assets/js/119.7b3b778d.js"><link rel="prefetch" href="/assets/js/12.8be56a9f.js"><link rel="prefetch" href="/assets/js/120.5bed53eb.js"><link rel="prefetch" href="/assets/js/121.6230467e.js"><link rel="prefetch" href="/assets/js/122.2b06e12b.js"><link rel="prefetch" href="/assets/js/123.c0c1408b.js"><link rel="prefetch" href="/assets/js/124.2b64250c.js"><link rel="prefetch" href="/assets/js/125.3ec84702.js"><link rel="prefetch" href="/assets/js/126.57fa9f85.js"><link rel="prefetch" href="/assets/js/127.d0880ce1.js"><link rel="prefetch" href="/assets/js/128.f0b0a8f0.js"><link rel="prefetch" href="/assets/js/129.25f8aa40.js"><link rel="prefetch" href="/assets/js/13.d4bf5523.js"><link rel="prefetch" href="/assets/js/130.add24ee3.js"><link rel="prefetch" href="/assets/js/131.4a7d930a.js"><link rel="prefetch" href="/assets/js/132.2d28192c.js"><link rel="prefetch" href="/assets/js/133.8ab0c59f.js"><link rel="prefetch" href="/assets/js/134.087f482e.js"><link rel="prefetch" href="/assets/js/135.561ceff2.js"><link rel="prefetch" href="/assets/js/136.d74b86c0.js"><link rel="prefetch" href="/assets/js/137.f6a5d77c.js"><link rel="prefetch" href="/assets/js/138.f1b87b7d.js"><link rel="prefetch" href="/assets/js/139.6c0ea80f.js"><link rel="prefetch" href="/assets/js/14.9cd73450.js"><link rel="prefetch" href="/assets/js/140.5ad7e28b.js"><link rel="prefetch" href="/assets/js/141.3046bae9.js"><link rel="prefetch" href="/assets/js/142.c7f90008.js"><link rel="prefetch" href="/assets/js/143.92bb40dd.js"><link rel="prefetch" href="/assets/js/144.aeafb587.js"><link rel="prefetch" href="/assets/js/145.41db90f2.js"><link rel="prefetch" href="/assets/js/146.aebd34dd.js"><link rel="prefetch" href="/assets/js/147.eeca1394.js"><link rel="prefetch" href="/assets/js/148.5eeeebe6.js"><link rel="prefetch" href="/assets/js/149.d3cf9d3d.js"><link rel="prefetch" href="/assets/js/15.5215bc7b.js"><link rel="prefetch" href="/assets/js/150.c9ca3dea.js"><link rel="prefetch" href="/assets/js/151.4d9c6877.js"><link rel="prefetch" href="/assets/js/152.8dcb3c6a.js"><link rel="prefetch" href="/assets/js/153.703c744c.js"><link rel="prefetch" href="/assets/js/154.3f515c62.js"><link rel="prefetch" href="/assets/js/155.c174dca3.js"><link rel="prefetch" href="/assets/js/156.56d4edb0.js"><link rel="prefetch" href="/assets/js/157.4453cfd9.js"><link rel="prefetch" href="/assets/js/158.19e56252.js"><link rel="prefetch" href="/assets/js/159.9b597726.js"><link rel="prefetch" href="/assets/js/16.fc53b5ae.js"><link rel="prefetch" href="/assets/js/160.befb4b17.js"><link rel="prefetch" href="/assets/js/161.c5664cb6.js"><link rel="prefetch" href="/assets/js/162.4b1d61e9.js"><link rel="prefetch" href="/assets/js/163.0514bf06.js"><link rel="prefetch" href="/assets/js/164.bf46b387.js"><link rel="prefetch" href="/assets/js/165.ebc1a907.js"><link rel="prefetch" href="/assets/js/166.67fc64cc.js"><link rel="prefetch" href="/assets/js/167.f4cba347.js"><link rel="prefetch" href="/assets/js/168.4887c1e0.js"><link rel="prefetch" href="/assets/js/169.e6834ace.js"><link rel="prefetch" href="/assets/js/17.6fbb9b3c.js"><link rel="prefetch" href="/assets/js/170.1f69d42d.js"><link rel="prefetch" href="/assets/js/171.39c0a2d9.js"><link rel="prefetch" href="/assets/js/172.c2ab41c1.js"><link rel="prefetch" href="/assets/js/173.dd50979a.js"><link rel="prefetch" href="/assets/js/174.e85080da.js"><link rel="prefetch" href="/assets/js/175.b989dd08.js"><link rel="prefetch" href="/assets/js/176.269f815e.js"><link rel="prefetch" href="/assets/js/177.1298b973.js"><link rel="prefetch" href="/assets/js/178.c37c4e7a.js"><link rel="prefetch" href="/assets/js/179.56587a82.js"><link rel="prefetch" href="/assets/js/18.10409789.js"><link rel="prefetch" href="/assets/js/180.1b27d417.js"><link rel="prefetch" href="/assets/js/181.94be7f4f.js"><link rel="prefetch" href="/assets/js/182.baeb4713.js"><link rel="prefetch" href="/assets/js/183.c3af5c0c.js"><link rel="prefetch" href="/assets/js/184.17c33787.js"><link rel="prefetch" href="/assets/js/185.6db69483.js"><link rel="prefetch" href="/assets/js/186.b43d0949.js"><link rel="prefetch" href="/assets/js/187.bb36d603.js"><link rel="prefetch" href="/assets/js/188.7511c1eb.js"><link rel="prefetch" href="/assets/js/189.d883d800.js"><link rel="prefetch" href="/assets/js/19.29348ac4.js"><link rel="prefetch" href="/assets/js/190.b766fbbd.js"><link rel="prefetch" href="/assets/js/191.d9ffa0e1.js"><link rel="prefetch" href="/assets/js/192.1bc18f80.js"><link rel="prefetch" href="/assets/js/193.f924e4f2.js"><link rel="prefetch" href="/assets/js/194.d2d25047.js"><link rel="prefetch" href="/assets/js/195.5ffe969b.js"><link rel="prefetch" href="/assets/js/196.5008c78f.js"><link rel="prefetch" href="/assets/js/197.6dc50349.js"><link rel="prefetch" href="/assets/js/198.daad4a75.js"><link rel="prefetch" href="/assets/js/199.86640c46.js"><link rel="prefetch" href="/assets/js/20.80914457.js"><link rel="prefetch" href="/assets/js/200.8dc9e5bd.js"><link rel="prefetch" href="/assets/js/201.8d2b2b9c.js"><link rel="prefetch" href="/assets/js/202.5b5a2066.js"><link rel="prefetch" href="/assets/js/203.fdef9efb.js"><link rel="prefetch" href="/assets/js/204.7c9be927.js"><link rel="prefetch" href="/assets/js/205.92a2f7b1.js"><link rel="prefetch" href="/assets/js/206.70dfcf68.js"><link rel="prefetch" href="/assets/js/207.d9b03878.js"><link rel="prefetch" href="/assets/js/208.3f18b820.js"><link rel="prefetch" href="/assets/js/209.280bbe21.js"><link rel="prefetch" href="/assets/js/21.ed7ca5a3.js"><link rel="prefetch" href="/assets/js/210.acfb25ea.js"><link rel="prefetch" href="/assets/js/22.b8ac78e1.js"><link rel="prefetch" href="/assets/js/23.94a709a6.js"><link rel="prefetch" href="/assets/js/24.9ea1d7f7.js"><link rel="prefetch" href="/assets/js/25.3c411f99.js"><link rel="prefetch" href="/assets/js/26.2e59bbe1.js"><link rel="prefetch" href="/assets/js/27.7bc7f0b4.js"><link rel="prefetch" href="/assets/js/28.c81c641f.js"><link rel="prefetch" href="/assets/js/29.50a31081.js"><link rel="prefetch" href="/assets/js/3.e5d236b4.js"><link rel="prefetch" href="/assets/js/30.1cbf66e9.js"><link rel="prefetch" href="/assets/js/31.b8f0e0c1.js"><link rel="prefetch" href="/assets/js/32.1f966a1e.js"><link rel="prefetch" href="/assets/js/33.2feb7fcd.js"><link rel="prefetch" href="/assets/js/34.2049dd0e.js"><link rel="prefetch" href="/assets/js/35.8dfb1673.js"><link rel="prefetch" href="/assets/js/36.fbe5cd9f.js"><link rel="prefetch" href="/assets/js/37.5823433f.js"><link rel="prefetch" href="/assets/js/38.0747c2f5.js"><link rel="prefetch" href="/assets/js/39.8c5f4bed.js"><link rel="prefetch" href="/assets/js/4.6bd5816f.js"><link rel="prefetch" href="/assets/js/40.6d77ae00.js"><link rel="prefetch" href="/assets/js/41.4f421a90.js"><link rel="prefetch" href="/assets/js/42.e7a8eea5.js"><link rel="prefetch" href="/assets/js/43.f1582549.js"><link rel="prefetch" href="/assets/js/44.28918b9c.js"><link rel="prefetch" href="/assets/js/45.de3bf837.js"><link rel="prefetch" href="/assets/js/46.9600de7e.js"><link rel="prefetch" href="/assets/js/47.275094f5.js"><link rel="prefetch" href="/assets/js/48.d2bea6ef.js"><link rel="prefetch" href="/assets/js/49.f8b43810.js"><link rel="prefetch" href="/assets/js/5.29aee12e.js"><link rel="prefetch" href="/assets/js/50.501279c5.js"><link rel="prefetch" href="/assets/js/51.a2d1d6ce.js"><link rel="prefetch" href="/assets/js/52.251fcdae.js"><link rel="prefetch" href="/assets/js/53.3e155b72.js"><link rel="prefetch" href="/assets/js/54.85eb423f.js"><link rel="prefetch" href="/assets/js/55.78b557fa.js"><link rel="prefetch" href="/assets/js/56.b33a97de.js"><link rel="prefetch" href="/assets/js/57.1095a666.js"><link rel="prefetch" href="/assets/js/58.f49361b3.js"><link rel="prefetch" href="/assets/js/59.5e26154a.js"><link rel="prefetch" href="/assets/js/6.1e84f4e9.js"><link rel="prefetch" href="/assets/js/60.0b60f098.js"><link rel="prefetch" href="/assets/js/61.2f41214f.js"><link rel="prefetch" href="/assets/js/62.961cdcef.js"><link rel="prefetch" href="/assets/js/63.349d6ce9.js"><link rel="prefetch" href="/assets/js/64.80929101.js"><link rel="prefetch" href="/assets/js/65.08474ebd.js"><link rel="prefetch" href="/assets/js/66.6e76a3d4.js"><link rel="prefetch" href="/assets/js/67.eebfa5ad.js"><link rel="prefetch" href="/assets/js/68.a958a889.js"><link rel="prefetch" href="/assets/js/69.81c1085c.js"><link rel="prefetch" href="/assets/js/7.02d0d177.js"><link rel="prefetch" href="/assets/js/70.01f0f7a6.js"><link rel="prefetch" href="/assets/js/71.edb53741.js"><link rel="prefetch" href="/assets/js/72.226e1455.js"><link rel="prefetch" href="/assets/js/73.e4545e79.js"><link rel="prefetch" href="/assets/js/74.2f045bac.js"><link rel="prefetch" href="/assets/js/76.5aeb4fd6.js"><link rel="prefetch" href="/assets/js/77.02253282.js"><link rel="prefetch" href="/assets/js/78.7b1b0bd3.js"><link rel="prefetch" href="/assets/js/79.816a2319.js"><link rel="prefetch" href="/assets/js/8.9ae73f65.js"><link rel="prefetch" href="/assets/js/80.a6c5273b.js"><link rel="prefetch" href="/assets/js/81.0e465d73.js"><link rel="prefetch" href="/assets/js/82.0256ceac.js"><link rel="prefetch" href="/assets/js/83.7c3b6b5e.js"><link rel="prefetch" href="/assets/js/84.45bc0d6d.js"><link rel="prefetch" href="/assets/js/85.a9dec703.js"><link rel="prefetch" href="/assets/js/86.b77ddae7.js"><link rel="prefetch" href="/assets/js/87.2777ef0b.js"><link rel="prefetch" href="/assets/js/88.a0c4778e.js"><link rel="prefetch" href="/assets/js/89.8edf4dc0.js"><link rel="prefetch" href="/assets/js/9.5b64cf14.js"><link rel="prefetch" href="/assets/js/90.dde4e78d.js"><link rel="prefetch" href="/assets/js/91.37fa1aed.js"><link rel="prefetch" href="/assets/js/92.33b5f64e.js"><link rel="prefetch" href="/assets/js/93.2f4d79a1.js"><link rel="prefetch" href="/assets/js/94.6358466c.js"><link rel="prefetch" href="/assets/js/95.0079f7dd.js"><link rel="prefetch" href="/assets/js/96.47781c88.js"><link rel="prefetch" href="/assets/js/97.c35ca98a.js"><link rel="prefetch" href="/assets/js/98.c3c4c28d.js"><link rel="prefetch" href="/assets/js/99.8bf03761.js">
    <link rel="stylesheet" href="/assets/css/0.styles.7cd537df.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">📖Documents</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>网络请求</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/network-request/http.html" class="sidebar-link">HTTP协议</a></li><li><a href="/python/network-request/urllib.html" class="sidebar-link">urllib库</a></li><li><a href="/python/network-request/requests.html" class="sidebar-link">requests库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据提取</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-extraction/xpath.html" class="sidebar-link">XPath语法</a></li><li><a href="/python/data-extraction/lxml.html" class="sidebar-link">lxml库</a></li><li><a href="/python/data-extraction/beautifulsoup.html" class="sidebar-link">BeautifulSoup库</a></li><li><a href="/python/data-extraction/regex.html" class="sidebar-link">Python中的正则表达式</a></li><li><a href="/python/data-extraction/python-re.html" class="sidebar-link">re模块</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据存储</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-storage/json.html" class="sidebar-link">json文件处理</a></li><li><a href="/python/data-storage/csv.html" class="sidebar-link">csv文件处理</a></li><li><a href="/python/data-storage/pymysql.html" class="sidebar-link">Python操作MySQL数据库</a></li><li><a href="/python/data-storage/mongodb.html" class="sidebar-link">Python操作MongoDB数据库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫进阶</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/multithreading.html" class="sidebar-link">多线程爬虫</a></li><li><a href="/python/spider/selenium.html" class="sidebar-link">动态网页爬虫</a></li><li><a href="/python/spider/tesseract.html" class="sidebar-link">图形验证码识别</a></li><li><a href="/python/spider/scrapy.html" aria-current="page" class="active sidebar-link">Scrapy框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架介绍" class="sidebar-link">Scrapy框架介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架模块功能" class="sidebar-link">Scrapy框架模块功能</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy安装和文档" class="sidebar-link">Scrapy安装和文档</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy快速入门" class="sidebar-link">Scrapy快速入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建项目" class="sidebar-link">创建项目</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#目录结构介绍" class="sidebar-link">目录结构介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#使用scrapy框架爬取糗事百科段子例子" class="sidebar-link">使用Scrapy框架爬取糗事百科段子例子</a></li></ul></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#jsonitemexporter和jsonlinesitemexporter" class="sidebar-link">JsonItemExporter和JsonLinesItemExporter</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy爬虫注意事项" class="sidebar-link">Scrapy爬虫注意事项</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#crawlspider" class="sidebar-link">CrawlSpider</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建crawlspider爬虫" class="sidebar-link">创建CrawlSpider爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#linkextractors链接提取器" class="sidebar-link">LinkExtractors链接提取器</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#rule规则类" class="sidebar-link">Rule规则类</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy-shell" class="sidebar-link">Scrapy Shell</a></li></ul></li><li><a href="/python/spider/scrapy-redis.html" class="sidebar-link">Scrapy-Redis分布式爬虫</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="scrapy框架"><a href="#scrapy框架" class="header-anchor">#</a> Scrapy框架</h1> <h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="header-anchor">#</a> Scrapy框架介绍</h2> <p>写一个爬虫，需要做很多的事情，比如：发送网络请求、数据解析、数据存储、反反爬虫机制(ip代理，设置请求头等)、异步请求等等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此scrapy把一些基础的东西都封装好了，在scrapy框架上开发爬虫可以变得更加的高效，爬取效率和开发效率得到提升。</p> <h2 id="scrapy框架模块功能"><a href="#scrapy框架模块功能" class="header-anchor">#</a> Scrapy框架模块功能</h2> <ul><li>Scrapy Engine（引擎）：Scrapy框架的核心部分。负责在Spider和ItemPipeline、Downloader、Scheduler中间通信、传递数据等。</li> <li>Spider（爬虫）：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li> <li>Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li> <li>Downloader（下载器）：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li> <li>Item Pipeline（管道）：负责将Spider（爬虫）传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li> <li>Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件。</li> <li>Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件。</li></ul> <h2 id="scrapy安装和文档"><a href="#scrapy安装和文档" class="header-anchor">#</a> Scrapy安装和文档</h2> <ul><li>安装：通过 <code>pip install scrapy</code> 即可安装。
<ul><li>在ubuntu上安装scrapy之前，需要先安装以下依赖：<code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过 <code>pip install scrapy</code> 安装。</li> <li>如果在windows系统下，提示这个错误ModuleNotFoundError: No module named 'win32api'，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li></ul></li> <li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener noreferrer">http://doc.scrapy.org/en/latest<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener noreferrer">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="scrapy快速入门"><a href="#scrapy快速入门" class="header-anchor">#</a> Scrapy快速入门</h2> <h3 id="创建项目"><a href="#创建项目" class="header-anchor">#</a> 创建项目</h3> <p>要使用Scrapy框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p> <p><code>scrapy startproject [项目名称]</code></p> <h3 id="目录结构介绍"><a href="#目录结构介绍" class="header-anchor">#</a> 目录结构介绍</h3> <ul><li>items.py：用来存放爬虫爬取下来数据的模型。</li> <li>middlewares.py：用来存放各种中间件的文件。</li> <li>pipelines.py：用来将items的模型存储到本地磁盘中。</li> <li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li> <li>scrapy.cfg：项目的配置文件。</li> <li>spiders包：以后所有的爬虫，都是存放到这个里面。</li></ul> <h3 id="使用scrapy框架爬取糗事百科段子例子"><a href="#使用scrapy框架爬取糗事百科段子例子" class="header-anchor">#</a> 使用Scrapy框架爬取糗事百科段子例子</h3> <h4 id="使用命令创建一个爬虫"><a href="#使用命令创建一个爬虫" class="header-anchor">#</a> 使用命令创建一个爬虫</h4> <p><code>scrapy gensipder qsbk &quot;qiushibaike.com&quot;</code></p> <p>创建了一个名字叫做 qsbk 的爬虫，并且能爬取的网页只会限制在 qiushibaike.com 这个域名下。</p> <h4 id="爬虫代码解析"><a href="#爬虫代码解析" class="header-anchor">#</a> 爬虫代码解析</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。</p> <p>要创建一个Spider，那么必须自定义一个类，继承自scrapy.Spider，然后在这个类中定义三个属性和一个方法。</p> <ul><li>name：这个爬虫的名字，名字必须是唯一的。</li> <li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li> <li>start_urls：爬虫从这个变量中的url开始。</li> <li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个parse方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li></ul> <h4 id="修改settings-py代码"><a href="#修改settings-py代码" class="header-anchor">#</a> 修改settings.py代码</h4> <p>在做一个爬虫之前，一定要记得修改setttings.py中的设置。两个地方是强烈建议设置的。</p> <ul><li>ROBOTSTXT_OBEY设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li> <li>DEFAULT_REQUEST_HEADERS添加User-Agent。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li></ul> <h4 id="完成的爬虫代码"><a href="#完成的爬虫代码" class="header-anchor">#</a> 完成的爬虫代码</h4> <h5 id="爬虫部分代码"><a href="#爬虫部分代码" class="header-anchor">#</a> 爬虫部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>response<span class="token punctuation">.</span>html <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>unified <span class="token keyword">import</span> SelectorList
<span class="token keyword">from</span> qsbk<span class="token punctuation">.</span>items <span class="token keyword">import</span> QsbkItem

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk_spider'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/page/1/'</span><span class="token punctuation">]</span>
    base_domain <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duanziDivs <span class="token operator">=</span> contentLeft <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//div[@id='content-left']/div&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> duanzidiv <span class="token keyword">in</span> duanziDivs<span class="token punctuation">:</span>
            author <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//h2/text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class='content']//text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># duanzi = {&quot;author&quot;:author,&quot;content&quot;:content}</span>
            <span class="token comment"># yield duanzi</span>

            item <span class="token operator">=</span> QsbkItem<span class="token punctuation">(</span>author<span class="token operator">=</span>author<span class="token punctuation">,</span>content<span class="token operator">=</span>content<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item
        next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ul[@class='pagination']/li[last()]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> next_url<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_domain <span class="token operator">+</span> next_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h5 id="items-py部分代码"><a href="#items-py部分代码" class="header-anchor">#</a> items.py部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h5 id="pipeline部分代码"><a href="#pipeline部分代码" class="header-anchor">#</a> pipeline部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 方式1</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item_json <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>item_json<span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式2</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式3</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonLinesItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><h4 id="运行scrapy项目"><a href="#运行scrapy项目" class="header-anchor">#</a> 运行scrapy项目</h4> <p>运行scrapy项目。需要在终端，进入项目所在的路径，然后 <code>scrapy crawl [爬虫名字]</code> 即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做 start.py，然后在这个文件中填入以下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl qsbk&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="jsonitemexporter和jsonlinesitemexporter"><a href="#jsonitemexporter和jsonlinesitemexporter" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExporter</h2> <ul><li>保存json数据的时候，可以使用这两个类，让操作变得更简单</li> <li><code>JsonItemExporter</code>：每次把数据添加到内存中，最后统一写入磁盘，存储的数据是一个满足json规则的数据，数据量比较大，比较耗内存</li> <li><code>JsonLinesItemExporter</code>：每次调用<code>export_item</code>的时候把这个item存储到磁盘，每一个字典是一行，整个文件不是一个满足json格式的文件，每次处理初级的时候直接存储到硬盘，不耗内存，数据比较安全</li></ul> <h2 id="scrapy爬虫注意事项"><a href="#scrapy爬虫注意事项" class="header-anchor">#</a> Scrapy爬虫注意事项</h2> <ul><li>response 是一个<code>from scrapy.http.response.html.HtmlResponse</code>对象，可以执行<code>xpath</code>和<code>css</code>语法提取数据</li> <li>提取出来的数据是一个<code>Selector</code>或者<code>SelectorList</code>对象，如果想要获取其中的字符串，应该执行<code>getall</code>或者<code>get</code>方法</li> <li>getall方法：获取<code>Selector</code>中所有文本，返回的是一个列表</li> <li>get方法：获取的是<code>Selector</code>中的第一个文本，返回的是str类型</li> <li>如果数据解析回来要传给pipelines处理，可以使用<code>yield</code>来返回，或者是添加所有的item，统一使用<code>return</code>返回</li> <li>item：在<code>item.py</code>中定义好模型，不要使用字典</li> <li>pipelines：这个是专门一从来保存数据的，其中有三个方法是会被经常用到的。要激活pipelines，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code> <ul><li><code>open_spider</code>：当爬虫被打开的时候执行</li> <li><code>process_item</code>：当爬虫有item传过来的时候会被调用</li> <li><code>close_spider</code>：当爬虫关闭的时候被调用</li></ul></li></ul> <h2 id="crawlspider"><a href="#crawlspider" class="header-anchor">#</a> CrawlSpider</h2> <p>在糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过CrawlSpider来帮我们完成了。CrawlSpider继承自Spider，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的yield Request。</p> <h2 id="创建crawlspider爬虫"><a href="#创建crawlspider爬虫" class="header-anchor">#</a> 创建CrawlSpider爬虫</h2> <p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建CrawlSpider爬虫，那么应该通过以下命令创建：</p> <p><code>scrapy genspider -c crawl [爬虫名字] [域名]</code></p> <h2 id="linkextractors链接提取器"><a href="#linkextractors链接提取器" class="header-anchor">#</a> LinkExtractors链接提取器</h2> <p>使用LinkExtractors可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给LinkExtractors，他会在所有爬的页面中找到满足规则的url，实现自动的爬取。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_extensions <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tags <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    attrs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    canonicalize <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    unique <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    process_value <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li> <li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li> <li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li> <li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li> <li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li></ul> <h2 id="rule规则类"><a href="#rule规则类" class="header-anchor">#</a> Rule规则类</h2> <p>定义爬虫的规则类。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>Rule<span class="token punctuation">(</span>
    link_extractor<span class="token punctuation">,</span>
    callback <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    cb_kwargs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    follow <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_links <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_request <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>link_extractor：一个LinkExtractor对象，用于定义爬取规则。</li> <li>callback：满足这个规则的url，应该要执行哪个回调函数。因为CrawlSpider使用了parse作为回调函数，因此不要覆盖parse作为回调函数自己的回调函数。</li> <li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li> <li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li></ul> <h2 id="scrapy-shell"><a href="#scrapy-shell" class="header-anchor">#</a> Scrapy Shell</h2> <p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为scrapy是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此Scrapy提供了一个shell，用来方便的测试规则</p> <p>打开cmd终端，进入到Scrapy项目所在的目录，然后进入到scrapy框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的parse方法中一样使用了。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/meowv/docs/edit/master//python/spider/scrapy.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">3 days ago</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/tesseract.html" class="prev">
        图形验证码识别
      </a></span> <span class="next"><a href="/python/spider/scrapy-redis.html">
        Scrapy-Redis分布式爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.2392be18.js" defer></script><script src="/assets/js/2.0955582b.js" defer></script><script src="/assets/js/75.aecfa217.js" defer></script>
  </body>
</html>
