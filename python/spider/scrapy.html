<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy框架 | 📖Documents</title>
    <meta name="generator" content="VuePress 1.5.3">
    <script>
        var _mtac = {"senseQuery":1};
        (function() {
            var mta = document.createElement("script");
            mta.src = "//pingjs.qq.com/h5/stats.js?v2.0.4";
            mta.setAttribute("name", "MTAH5");
            mta.setAttribute("sid", "500727760");
            mta.setAttribute("cid", "500727761");
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(mta, s);
        })();
        </script>
    <meta name="description" content="This is a personal document library for development work">
    <link rel="preload" href="/assets/css/0.styles.7cd537df.css" as="style"><link rel="preload" href="/assets/js/app.688d7ea9.js" as="script"><link rel="preload" href="/assets/js/2.8ee08ab2.js" as="script"><link rel="preload" href="/assets/js/72.d662c1d0.js" as="script"><link rel="prefetch" href="/assets/js/10.f7320c53.js"><link rel="prefetch" href="/assets/js/100.a3894415.js"><link rel="prefetch" href="/assets/js/101.55c204ff.js"><link rel="prefetch" href="/assets/js/102.df38530f.js"><link rel="prefetch" href="/assets/js/103.10d5b13f.js"><link rel="prefetch" href="/assets/js/104.ff9f60ec.js"><link rel="prefetch" href="/assets/js/105.4ce5ee06.js"><link rel="prefetch" href="/assets/js/106.40eaea99.js"><link rel="prefetch" href="/assets/js/107.45915dac.js"><link rel="prefetch" href="/assets/js/108.a4b8f8d6.js"><link rel="prefetch" href="/assets/js/109.2e2a932f.js"><link rel="prefetch" href="/assets/js/11.c505a573.js"><link rel="prefetch" href="/assets/js/110.b9b8c0fc.js"><link rel="prefetch" href="/assets/js/111.9f1c7f5b.js"><link rel="prefetch" href="/assets/js/112.16091eaf.js"><link rel="prefetch" href="/assets/js/113.82d2a091.js"><link rel="prefetch" href="/assets/js/114.619a81ed.js"><link rel="prefetch" href="/assets/js/115.6d739b2e.js"><link rel="prefetch" href="/assets/js/116.3b196711.js"><link rel="prefetch" href="/assets/js/117.752405fb.js"><link rel="prefetch" href="/assets/js/118.a55f2b11.js"><link rel="prefetch" href="/assets/js/119.c1a71b0d.js"><link rel="prefetch" href="/assets/js/12.55de9084.js"><link rel="prefetch" href="/assets/js/120.91afabb8.js"><link rel="prefetch" href="/assets/js/121.7cc1e95d.js"><link rel="prefetch" href="/assets/js/122.18d56d87.js"><link rel="prefetch" href="/assets/js/123.c3e3000e.js"><link rel="prefetch" href="/assets/js/124.4e34aa05.js"><link rel="prefetch" href="/assets/js/125.b24810bc.js"><link rel="prefetch" href="/assets/js/126.58b44c22.js"><link rel="prefetch" href="/assets/js/127.ff2f9a61.js"><link rel="prefetch" href="/assets/js/128.cfc2d998.js"><link rel="prefetch" href="/assets/js/129.808a1352.js"><link rel="prefetch" href="/assets/js/13.715e98f9.js"><link rel="prefetch" href="/assets/js/130.0a18f159.js"><link rel="prefetch" href="/assets/js/131.0ec3210e.js"><link rel="prefetch" href="/assets/js/132.5a8c7642.js"><link rel="prefetch" href="/assets/js/133.6b44581e.js"><link rel="prefetch" href="/assets/js/134.89a2750f.js"><link rel="prefetch" href="/assets/js/135.4314b526.js"><link rel="prefetch" href="/assets/js/136.8832bf59.js"><link rel="prefetch" href="/assets/js/137.4f10c6fd.js"><link rel="prefetch" href="/assets/js/138.d470979d.js"><link rel="prefetch" href="/assets/js/139.83b1e9e9.js"><link rel="prefetch" href="/assets/js/14.24969a4e.js"><link rel="prefetch" href="/assets/js/140.19968965.js"><link rel="prefetch" href="/assets/js/141.40a83e5d.js"><link rel="prefetch" href="/assets/js/142.f144a1a2.js"><link rel="prefetch" href="/assets/js/143.e22c35ef.js"><link rel="prefetch" href="/assets/js/144.4cfc306b.js"><link rel="prefetch" href="/assets/js/145.a455bfbb.js"><link rel="prefetch" href="/assets/js/146.805e8089.js"><link rel="prefetch" href="/assets/js/147.645fc169.js"><link rel="prefetch" href="/assets/js/148.9688b039.js"><link rel="prefetch" href="/assets/js/149.72cc609c.js"><link rel="prefetch" href="/assets/js/15.e948de7b.js"><link rel="prefetch" href="/assets/js/150.bf202f09.js"><link rel="prefetch" href="/assets/js/151.b978ca49.js"><link rel="prefetch" href="/assets/js/152.41739c90.js"><link rel="prefetch" href="/assets/js/153.e0a4a95a.js"><link rel="prefetch" href="/assets/js/154.4eb73aff.js"><link rel="prefetch" href="/assets/js/155.3ba7c46d.js"><link rel="prefetch" href="/assets/js/156.497308e6.js"><link rel="prefetch" href="/assets/js/157.883181be.js"><link rel="prefetch" href="/assets/js/158.76374f5b.js"><link rel="prefetch" href="/assets/js/159.7eb11d18.js"><link rel="prefetch" href="/assets/js/16.ce8ba54c.js"><link rel="prefetch" href="/assets/js/160.d24afc1a.js"><link rel="prefetch" href="/assets/js/161.7fca0e42.js"><link rel="prefetch" href="/assets/js/162.94455b10.js"><link rel="prefetch" href="/assets/js/163.54367d11.js"><link rel="prefetch" href="/assets/js/164.d6984bcd.js"><link rel="prefetch" href="/assets/js/165.57b90c00.js"><link rel="prefetch" href="/assets/js/166.3e9a4fa8.js"><link rel="prefetch" href="/assets/js/167.3090f1d3.js"><link rel="prefetch" href="/assets/js/168.4066243f.js"><link rel="prefetch" href="/assets/js/169.5e50938a.js"><link rel="prefetch" href="/assets/js/17.54826cbc.js"><link rel="prefetch" href="/assets/js/170.b2f39298.js"><link rel="prefetch" href="/assets/js/171.d7ac0aef.js"><link rel="prefetch" href="/assets/js/172.8a626b0b.js"><link rel="prefetch" href="/assets/js/173.2f47dfcf.js"><link rel="prefetch" href="/assets/js/174.c7d70f5d.js"><link rel="prefetch" href="/assets/js/175.33842f62.js"><link rel="prefetch" href="/assets/js/176.0c82777c.js"><link rel="prefetch" href="/assets/js/177.4f818d73.js"><link rel="prefetch" href="/assets/js/178.cb08e18d.js"><link rel="prefetch" href="/assets/js/179.4a9aa37d.js"><link rel="prefetch" href="/assets/js/18.b41d9eab.js"><link rel="prefetch" href="/assets/js/180.a0c6afd3.js"><link rel="prefetch" href="/assets/js/181.e079d8b9.js"><link rel="prefetch" href="/assets/js/182.a10c0a9c.js"><link rel="prefetch" href="/assets/js/183.395c0b13.js"><link rel="prefetch" href="/assets/js/184.88766c93.js"><link rel="prefetch" href="/assets/js/185.d99d5cb2.js"><link rel="prefetch" href="/assets/js/186.82b46391.js"><link rel="prefetch" href="/assets/js/187.f95d563a.js"><link rel="prefetch" href="/assets/js/188.72f6e97c.js"><link rel="prefetch" href="/assets/js/189.c9c75904.js"><link rel="prefetch" href="/assets/js/19.6ca2b84b.js"><link rel="prefetch" href="/assets/js/190.c8255e5c.js"><link rel="prefetch" href="/assets/js/191.e9e836d2.js"><link rel="prefetch" href="/assets/js/192.9a99dd9a.js"><link rel="prefetch" href="/assets/js/193.77012039.js"><link rel="prefetch" href="/assets/js/194.7d551d3e.js"><link rel="prefetch" href="/assets/js/195.c5b41b80.js"><link rel="prefetch" href="/assets/js/196.94064cf7.js"><link rel="prefetch" href="/assets/js/197.0d8da22b.js"><link rel="prefetch" href="/assets/js/198.823b7dd1.js"><link rel="prefetch" href="/assets/js/199.7dfc8e56.js"><link rel="prefetch" href="/assets/js/20.e3b834ad.js"><link rel="prefetch" href="/assets/js/200.6d59361c.js"><link rel="prefetch" href="/assets/js/201.f673d63f.js"><link rel="prefetch" href="/assets/js/202.c33fdb63.js"><link rel="prefetch" href="/assets/js/203.7b8b2f42.js"><link rel="prefetch" href="/assets/js/204.d3bb3c05.js"><link rel="prefetch" href="/assets/js/205.3e90c6b0.js"><link rel="prefetch" href="/assets/js/206.07f755e6.js"><link rel="prefetch" href="/assets/js/207.6dd04ed3.js"><link rel="prefetch" href="/assets/js/208.4fabc73b.js"><link rel="prefetch" href="/assets/js/209.c67002e4.js"><link rel="prefetch" href="/assets/js/21.e2ce0f58.js"><link rel="prefetch" href="/assets/js/210.aae1507d.js"><link rel="prefetch" href="/assets/js/22.4cc0f431.js"><link rel="prefetch" href="/assets/js/23.9f26f818.js"><link rel="prefetch" href="/assets/js/24.c2862c5a.js"><link rel="prefetch" href="/assets/js/25.8a4429a4.js"><link rel="prefetch" href="/assets/js/26.3da2b975.js"><link rel="prefetch" href="/assets/js/27.88b7470e.js"><link rel="prefetch" href="/assets/js/28.45117cd3.js"><link rel="prefetch" href="/assets/js/29.38f2c7e1.js"><link rel="prefetch" href="/assets/js/3.859d7299.js"><link rel="prefetch" href="/assets/js/30.72f1d3ac.js"><link rel="prefetch" href="/assets/js/31.6f635b22.js"><link rel="prefetch" href="/assets/js/32.c5ddf8fd.js"><link rel="prefetch" href="/assets/js/33.944b9a9c.js"><link rel="prefetch" href="/assets/js/34.ee92a794.js"><link rel="prefetch" href="/assets/js/35.12ee5220.js"><link rel="prefetch" href="/assets/js/36.76bb288b.js"><link rel="prefetch" href="/assets/js/37.6c42194b.js"><link rel="prefetch" href="/assets/js/38.9dd05ef0.js"><link rel="prefetch" href="/assets/js/39.298b8886.js"><link rel="prefetch" href="/assets/js/4.eaa6f5dd.js"><link rel="prefetch" href="/assets/js/40.65dd9d47.js"><link rel="prefetch" href="/assets/js/41.0c98d2e3.js"><link rel="prefetch" href="/assets/js/42.80ea8543.js"><link rel="prefetch" href="/assets/js/43.107d9baf.js"><link rel="prefetch" href="/assets/js/44.18a0607b.js"><link rel="prefetch" href="/assets/js/45.99c44300.js"><link rel="prefetch" href="/assets/js/46.39fd493f.js"><link rel="prefetch" href="/assets/js/47.56403662.js"><link rel="prefetch" href="/assets/js/48.40891065.js"><link rel="prefetch" href="/assets/js/49.aa239a6f.js"><link rel="prefetch" href="/assets/js/5.82493ede.js"><link rel="prefetch" href="/assets/js/50.ab69f368.js"><link rel="prefetch" href="/assets/js/51.b28f1da9.js"><link rel="prefetch" href="/assets/js/52.a989c384.js"><link rel="prefetch" href="/assets/js/53.04d526ea.js"><link rel="prefetch" href="/assets/js/54.b69b3b72.js"><link rel="prefetch" href="/assets/js/55.042c0c00.js"><link rel="prefetch" href="/assets/js/56.710a90c0.js"><link rel="prefetch" href="/assets/js/57.90a5a0c5.js"><link rel="prefetch" href="/assets/js/58.6ae0ff65.js"><link rel="prefetch" href="/assets/js/59.19cdbf62.js"><link rel="prefetch" href="/assets/js/6.ae501498.js"><link rel="prefetch" href="/assets/js/60.d1eb52c0.js"><link rel="prefetch" href="/assets/js/61.e66fee01.js"><link rel="prefetch" href="/assets/js/62.51704438.js"><link rel="prefetch" href="/assets/js/63.f9e214d8.js"><link rel="prefetch" href="/assets/js/64.64a6adf1.js"><link rel="prefetch" href="/assets/js/65.ba64cb36.js"><link rel="prefetch" href="/assets/js/66.98264db1.js"><link rel="prefetch" href="/assets/js/67.12c2a16d.js"><link rel="prefetch" href="/assets/js/68.ec2e3494.js"><link rel="prefetch" href="/assets/js/69.07b8781a.js"><link rel="prefetch" href="/assets/js/7.e4240742.js"><link rel="prefetch" href="/assets/js/70.8dd408bb.js"><link rel="prefetch" href="/assets/js/71.7e39c9fb.js"><link rel="prefetch" href="/assets/js/73.79e53998.js"><link rel="prefetch" href="/assets/js/74.ff01611c.js"><link rel="prefetch" href="/assets/js/75.62d0c8f1.js"><link rel="prefetch" href="/assets/js/76.abf24994.js"><link rel="prefetch" href="/assets/js/77.65953bf8.js"><link rel="prefetch" href="/assets/js/78.d5850a58.js"><link rel="prefetch" href="/assets/js/79.8dbc211b.js"><link rel="prefetch" href="/assets/js/8.de9255d4.js"><link rel="prefetch" href="/assets/js/80.6884833a.js"><link rel="prefetch" href="/assets/js/81.0cb76582.js"><link rel="prefetch" href="/assets/js/82.c713be38.js"><link rel="prefetch" href="/assets/js/83.29d079ce.js"><link rel="prefetch" href="/assets/js/84.83a1eeb1.js"><link rel="prefetch" href="/assets/js/85.f8c76241.js"><link rel="prefetch" href="/assets/js/86.6b4cb898.js"><link rel="prefetch" href="/assets/js/87.d16f7498.js"><link rel="prefetch" href="/assets/js/88.3a84ea63.js"><link rel="prefetch" href="/assets/js/89.6594e262.js"><link rel="prefetch" href="/assets/js/9.382b4b07.js"><link rel="prefetch" href="/assets/js/90.a0db2154.js"><link rel="prefetch" href="/assets/js/91.1bfe6107.js"><link rel="prefetch" href="/assets/js/92.bb748ce8.js"><link rel="prefetch" href="/assets/js/93.a31b4566.js"><link rel="prefetch" href="/assets/js/94.533efba4.js"><link rel="prefetch" href="/assets/js/95.f6504721.js"><link rel="prefetch" href="/assets/js/96.6777e87a.js"><link rel="prefetch" href="/assets/js/97.e5fd2336.js"><link rel="prefetch" href="/assets/js/98.5a93ec9c.js"><link rel="prefetch" href="/assets/js/99.35484db4.js">
    <link rel="stylesheet" href="/assets/css/0.styles.7cd537df.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">📖Documents</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⚡系列文章" class="dropdown-title"><span class="title">⚡系列文章</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/aspnetcore/abp-blog/" class="nav-link">
  🚀基于 abp vNext 和 .NET Core 开发博客项目
</a></li></ul></div></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  🎈Python
</a></div><div class="nav-item"><a href="/stack/" class="nav-link">
  🍺技术栈
</a></div><div class="nav-item"><a href="/summary/" class="nav-link">
  🎉总结
</a></div> <a href="https://github.com/meowv/docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    ⭐️GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>网络请求</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/network-request/http.html" class="sidebar-link">HTTP协议</a></li><li><a href="/python/network-request/urllib.html" class="sidebar-link">urllib库</a></li><li><a href="/python/network-request/requests.html" class="sidebar-link">requests库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据提取</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-extraction/xpath.html" class="sidebar-link">XPath语法</a></li><li><a href="/python/data-extraction/lxml.html" class="sidebar-link">lxml库</a></li><li><a href="/python/data-extraction/beautifulsoup.html" class="sidebar-link">BeautifulSoup库</a></li><li><a href="/python/data-extraction/regex.html" class="sidebar-link">Python中的正则表达式</a></li><li><a href="/python/data-extraction/python-re.html" class="sidebar-link">re模块</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据存储</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/data-storage/json.html" class="sidebar-link">json文件处理</a></li><li><a href="/python/data-storage/csv.html" class="sidebar-link">csv文件处理</a></li><li><a href="/python/data-storage/pymysql.html" class="sidebar-link">Python操作MySQL数据库</a></li><li><a href="/python/data-storage/mongodb.html" class="sidebar-link">Python操作MongoDB数据库</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>爬虫进阶</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/multithreading.html" class="sidebar-link">多线程爬虫</a></li><li><a href="/python/spider/selenium.html" class="sidebar-link">动态网页爬虫</a></li><li><a href="/python/spider/tesseract.html" class="sidebar-link">图形验证码识别</a></li><li><a href="/python/spider/scrapy.html" aria-current="page" class="active sidebar-link">Scrapy框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架介绍" class="sidebar-link">Scrapy框架介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy框架模块功能" class="sidebar-link">Scrapy框架模块功能</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy安装和文档" class="sidebar-link">Scrapy安装和文档</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy快速入门" class="sidebar-link">Scrapy快速入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建项目" class="sidebar-link">创建项目</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#目录结构介绍" class="sidebar-link">目录结构介绍</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#使用scrapy框架爬取糗事百科段子例子" class="sidebar-link">使用Scrapy框架爬取糗事百科段子例子</a></li></ul></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#jsonitemexporter和jsonlinesitemexporter" class="sidebar-link">JsonItemExporter和JsonLinesItemExporter</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy爬虫注意事项" class="sidebar-link">Scrapy爬虫注意事项</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#crawlspider" class="sidebar-link">CrawlSpider</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#创建crawlspider爬虫" class="sidebar-link">创建CrawlSpider爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#linkextractors链接提取器" class="sidebar-link">LinkExtractors链接提取器</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#rule规则类" class="sidebar-link">Rule规则类</a></li><li class="sidebar-sub-header"><a href="/python/spider/scrapy.html#scrapy-shell" class="sidebar-link">Scrapy Shell</a></li></ul></li><li><a href="/python/spider/scrapy-redis.html" class="sidebar-link">Scrapy-Redis分布式爬虫</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="scrapy框架"><a href="#scrapy框架" class="header-anchor">#</a> Scrapy框架</h1> <h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="header-anchor">#</a> Scrapy框架介绍</h2> <p>写一个爬虫，需要做很多的事情，比如：发送网络请求、数据解析、数据存储、反反爬虫机制(ip代理，设置请求头等)、异步请求等等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此scrapy把一些基础的东西都封装好了，在scrapy框架上开发爬虫可以变得更加的高效，爬取效率和开发效率得到提升。</p> <h2 id="scrapy框架模块功能"><a href="#scrapy框架模块功能" class="header-anchor">#</a> Scrapy框架模块功能</h2> <ul><li>Scrapy Engine（引擎）：Scrapy框架的核心部分。负责在Spider和ItemPipeline、Downloader、Scheduler中间通信、传递数据等。</li> <li>Spider（爬虫）：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li> <li>Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li> <li>Downloader（下载器）：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li> <li>Item Pipeline（管道）：负责将Spider（爬虫）传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li> <li>Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件。</li> <li>Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件。</li></ul> <h2 id="scrapy安装和文档"><a href="#scrapy安装和文档" class="header-anchor">#</a> Scrapy安装和文档</h2> <ul><li>安装：通过 <code>pip install scrapy</code> 即可安装。
<ul><li>在ubuntu上安装scrapy之前，需要先安装以下依赖：<code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过 <code>pip install scrapy</code> 安装。</li> <li>如果在windows系统下，提示这个错误ModuleNotFoundError: No module named 'win32api'，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li></ul></li> <li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener noreferrer">http://doc.scrapy.org/en/latest<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener noreferrer">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="scrapy快速入门"><a href="#scrapy快速入门" class="header-anchor">#</a> Scrapy快速入门</h2> <h3 id="创建项目"><a href="#创建项目" class="header-anchor">#</a> 创建项目</h3> <p>要使用Scrapy框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p> <p><code>scrapy startproject [项目名称]</code></p> <h3 id="目录结构介绍"><a href="#目录结构介绍" class="header-anchor">#</a> 目录结构介绍</h3> <ul><li>items.py：用来存放爬虫爬取下来数据的模型。</li> <li>middlewares.py：用来存放各种中间件的文件。</li> <li>pipelines.py：用来将items的模型存储到本地磁盘中。</li> <li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li> <li>scrapy.cfg：项目的配置文件。</li> <li>spiders包：以后所有的爬虫，都是存放到这个里面。</li></ul> <h3 id="使用scrapy框架爬取糗事百科段子例子"><a href="#使用scrapy框架爬取糗事百科段子例子" class="header-anchor">#</a> 使用Scrapy框架爬取糗事百科段子例子</h3> <h4 id="使用命令创建一个爬虫"><a href="#使用命令创建一个爬虫" class="header-anchor">#</a> 使用命令创建一个爬虫</h4> <p><code>scrapy gensipder qsbk &quot;qiushibaike.com&quot;</code></p> <p>创建了一个名字叫做 qsbk 的爬虫，并且能爬取的网页只会限制在 qiushibaike.com 这个域名下。</p> <h4 id="爬虫代码解析"><a href="#爬虫代码解析" class="header-anchor">#</a> 爬虫代码解析</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。</p> <p>要创建一个Spider，那么必须自定义一个类，继承自scrapy.Spider，然后在这个类中定义三个属性和一个方法。</p> <ul><li>name：这个爬虫的名字，名字必须是唯一的。</li> <li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li> <li>start_urls：爬虫从这个变量中的url开始。</li> <li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个parse方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li></ul> <h4 id="修改settings-py代码"><a href="#修改settings-py代码" class="header-anchor">#</a> 修改settings.py代码</h4> <p>在做一个爬虫之前，一定要记得修改setttings.py中的设置。两个地方是强烈建议设置的。</p> <ul><li>ROBOTSTXT_OBEY设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li> <li>DEFAULT_REQUEST_HEADERS添加User-Agent。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li></ul> <h4 id="完成的爬虫代码"><a href="#完成的爬虫代码" class="header-anchor">#</a> 完成的爬虫代码</h4> <h5 id="爬虫部分代码"><a href="#爬虫部分代码" class="header-anchor">#</a> 爬虫部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>response<span class="token punctuation">.</span>html <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>unified <span class="token keyword">import</span> SelectorList
<span class="token keyword">from</span> qsbk<span class="token punctuation">.</span>items <span class="token keyword">import</span> QsbkItem

<span class="token keyword">class</span> <span class="token class-name">QsbkSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qsbk_spider'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'qiushibaike.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/page/1/'</span><span class="token punctuation">]</span>
    base_domain <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        duanziDivs <span class="token operator">=</span> contentLeft <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//div[@id='content-left']/div&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> duanzidiv <span class="token keyword">in</span> duanziDivs<span class="token punctuation">:</span>
            author <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//h2/text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> duanzidiv<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class='content']//text()&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># duanzi = {&quot;author&quot;:author,&quot;content&quot;:content}</span>
            <span class="token comment"># yield duanzi</span>

            item <span class="token operator">=</span> QsbkItem<span class="token punctuation">(</span>author<span class="token operator">=</span>author<span class="token punctuation">,</span>content<span class="token operator">=</span>content<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item
        next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ul[@class='pagination']/li[last()]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> next_url<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_domain <span class="token operator">+</span> next_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h5 id="items-py部分代码"><a href="#items-py部分代码" class="header-anchor">#</a> items.py部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QsbkItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h5 id="pipeline部分代码"><a href="#pipeline部分代码" class="header-anchor">#</a> pipeline部分代码</h5> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 方式1</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item_json <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>item_json<span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式2</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>

<span class="token comment"># 方式3</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exporters <span class="token keyword">import</span> JsonLinesItemExporter
<span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.josn&quot;</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start...'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'end...'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><h4 id="运行scrapy项目"><a href="#运行scrapy项目" class="header-anchor">#</a> 运行scrapy项目</h4> <p>运行scrapy项目。需要在终端，进入项目所在的路径，然后 <code>scrapy crawl [爬虫名字]</code> 即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做 start.py，然后在这个文件中填入以下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl qsbk&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="jsonitemexporter和jsonlinesitemexporter"><a href="#jsonitemexporter和jsonlinesitemexporter" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExporter</h2> <ul><li>保存json数据的时候，可以使用这两个类，让操作变得更简单</li> <li><code>JsonItemExporter</code>：每次把数据添加到内存中，最后统一写入磁盘，存储的数据是一个满足json规则的数据，数据量比较大，比较耗内存</li> <li><code>JsonLinesItemExporter</code>：每次调用<code>export_item</code>的时候把这个item存储到磁盘，每一个字典是一行，整个文件不是一个满足json格式的文件，每次处理初级的时候直接存储到硬盘，不耗内存，数据比较安全</li></ul> <h2 id="scrapy爬虫注意事项"><a href="#scrapy爬虫注意事项" class="header-anchor">#</a> Scrapy爬虫注意事项</h2> <ul><li>response 是一个<code>from scrapy.http.response.html.HtmlResponse</code>对象，可以执行<code>xpath</code>和<code>css</code>语法提取数据</li> <li>提取出来的数据是一个<code>Selector</code>或者<code>SelectorList</code>对象，如果想要获取其中的字符串，应该执行<code>getall</code>或者<code>get</code>方法</li> <li>getall方法：获取<code>Selector</code>中所有文本，返回的是一个列表</li> <li>get方法：获取的是<code>Selector</code>中的第一个文本，返回的是str类型</li> <li>如果数据解析回来要传给pipelines处理，可以使用<code>yield</code>来返回，或者是添加所有的item，统一使用<code>return</code>返回</li> <li>item：在<code>item.py</code>中定义好模型，不要使用字典</li> <li>pipelines：这个是专门一从来保存数据的，其中有三个方法是会被经常用到的。要激活pipelines，应该在<code>settings.py</code>中，设置<code>ITEM_PIPELINES</code> <ul><li><code>open_spider</code>：当爬虫被打开的时候执行</li> <li><code>process_item</code>：当爬虫有item传过来的时候会被调用</li> <li><code>close_spider</code>：当爬虫关闭的时候被调用</li></ul></li></ul> <h2 id="crawlspider"><a href="#crawlspider" class="header-anchor">#</a> CrawlSpider</h2> <p>在糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过CrawlSpider来帮我们完成了。CrawlSpider继承自Spider，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的yield Request。</p> <h2 id="创建crawlspider爬虫"><a href="#创建crawlspider爬虫" class="header-anchor">#</a> 创建CrawlSpider爬虫</h2> <p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建CrawlSpider爬虫，那么应该通过以下命令创建：</p> <p><code>scrapy genspider -c crawl [爬虫名字] [域名]</code></p> <h2 id="linkextractors链接提取器"><a href="#linkextractors链接提取器" class="header-anchor">#</a> LinkExtractors链接提取器</h2> <p>使用LinkExtractors可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给LinkExtractors，他会在所有爬的页面中找到满足规则的url，实现自动的爬取。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>LinkExtractor<span class="token punctuation">(</span>
    allow <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    allow_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_domains <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    deny_extensions <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    restrict_xpaths <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tags <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    attrs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    canonicalize <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    unique <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    process_value <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li> <li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li> <li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li> <li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li> <li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li></ul> <h2 id="rule规则类"><a href="#rule规则类" class="header-anchor">#</a> Rule规则类</h2> <p>定义爬虫的规则类。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">scrapy</span><span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>Rule<span class="token punctuation">(</span>
    link_extractor<span class="token punctuation">,</span>
    callback <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    cb_kwargs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    follow <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_links <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    process_request <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>link_extractor：一个LinkExtractor对象，用于定义爬取规则。</li> <li>callback：满足这个规则的url，应该要执行哪个回调函数。因为CrawlSpider使用了parse作为回调函数，因此不要覆盖parse作为回调函数自己的回调函数。</li> <li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li> <li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li></ul> <h2 id="scrapy-shell"><a href="#scrapy-shell" class="header-anchor">#</a> Scrapy Shell</h2> <p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为scrapy是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此Scrapy提供了一个shell，用来方便的测试规则</p> <p>打开cmd终端，进入到Scrapy项目所在的目录，然后进入到scrapy框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的parse方法中一样使用了。</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/meowv/docs/edit/master//python/spider/scrapy.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">3 days ago</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/tesseract.html" class="prev">
        图形验证码识别
      </a></span> <span class="next"><a href="/python/spider/scrapy-redis.html">
        Scrapy-Redis分布式爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.688d7ea9.js" defer></script><script src="/assets/js/2.8ee08ab2.js" defer></script><script src="/assets/js/72.d662c1d0.js" defer></script>
  </body>
</html>
